{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15272a9-ef9c-4e9e-b7ac-9d93ad331454",
   "metadata": {},
   "source": [
    "<H1> CrystallineMLAlone.ipynb </H1>\n",
    "\n",
    "This code requires that CrystallineFileLectureTests.ipynb has been run. As the data base is extremely small, the effects of overfitting and underfitting are very prone to happening. To test if a model performs as expected it should try to predict files that have not been used in the process of training and validation. As we can't extract too many files form the data base, the solution is to extract the n-th experiment, train a model with a given structure with all the other experiments, try to predict this isolated experiment (a blind prediction where we know what the output should be) and repeat the process for all experiments. To compare the results of different models please use the code files inside LTestVisualCheck\n",
    "\n",
    "__________________________________________________________________________________________\n",
    "\n",
    "OUTPUTS OF THE CODE: \n",
    "\n",
    "1. CrystallineLog_Testing_ML.txt\n",
    "A log file with every step that the algorithm has followed\n",
    "\n",
    "\n",
    "2. CrystallineExecution_times.txt\n",
    "It times how long the code took to loop for each model to loop over all the isolation \n",
    "\n",
    "\n",
    "3. CrystallineAllTestsFolder_{Complexity}_{num_augmentations} \n",
    "For each Complexity and each num_augmentations (a.k.a, for each model structure and data organization) a folder is created. Inside there are folders for each isolated experiment iteration\n",
    "\n",
    "3.1 Missing{base_name}\n",
    "For each experiment in the data base (CrystallineMLDataBase) a folder is created and inside there are all the files that the code has created when training and predicting\n",
    " \n",
    "3.1.1 Difference_{base_name}.jpg\n",
    "For each experimental point, we obtain the prediction and we obtain the difference between prediction and experimental values. It may be helpful to detect an overall deficiency when predicting\n",
    "\n",
    "3.1.2 Difference_{base_name}.txt\n",
    "Has the same information as the last .jpg but written on a .txt file\n",
    "\n",
    "3.1.3 Missing_{base_name}.jpg\n",
    "This is the important graph. It shows in black the experimental values with their uncertainty, in red the pure ML predictions (without the correction) with the uncertainty bands in a transparent red, in green the final predictions (ML + linear correction) with uncertainty as the green transparent band and in blue the corrected predictions for the time points where experimental values are known\n",
    "\n",
    "3.1.4 PredictedData_PolarizationD3_Missing{base_name}.txt\n",
    "The green part of the graph but in a .txt file\n",
    "\n",
    "3.1.5 PredictedPoints_PolarizationD3_Missing{base_name}.txt\n",
    "The blue part of the graph but in a .txt file\n",
    "\n",
    "3.1.6 RawData_PolarizationD3_Missing{base_name}.txt\n",
    "The black part of the graph but in a .txt file. It is supposed to be a duplicate of the file in CrystallineMLDataBase but it is stored to make sure that the scaling process is being done accurately (if it doesn't fit, be very very careful)\n",
    "\n",
    "3.1.7 model_PolarizationD3.keras\n",
    "The model used in this isolated-experiment iteration\n",
    "\n",
    "3.1.8 scaler_static_PolarizationD3.pkl\n",
    "The scaler for the static parameters (initial and final polarizations included) used in this isolated-experiment iteration\n",
    "\n",
    "3.1.9 scaler_time_PolarizationD3.pkl\n",
    "The scaler for the time evolution used in this isolated-experiment iteration\n",
    "\n",
    "3.1.10 scaler_y_PolarizationD3.pkl\n",
    "The scaler for the polarization values used in this isolated-experiment iteration\n",
    "\n",
    "\n",
    "__________________________________________________________________________________________\n",
    "\n",
    "\n",
    "Process:\n",
    "\n",
    "1. Read the {base_name}.txt and {base_name}_Parameters.txt from CrystallineMLDataBase (running CrystallineFileLectureTests.ipynb in its folder is COMPULSARY)\n",
    "\n",
    "2. Choose to use PolarizationD3 or SoftPolarizationD3 (always use the first one as it is a more natural approach)\n",
    "\n",
    "3. Choose an experiment to isolate (this process is looped over all experiments so all experiments become the isolated one at one point or another)\n",
    "\n",
    "4. Scaling. The code needs normalization to work so the parameters (or static vector), the time values and the polarization values need to be normalized. There are many ways to choose the normalization process. Especially since we are going to add the first and last polarization measurement to the static vector. Here is the reasoning:\n",
    "When this algorythm is used, we will give it the same parameter types and the beginning and final polarization. Therefore the wisest approach is to teach the model with this\n",
    "exact structure. Therefore it is needed that we extract the initial and final polarization from the files and add it into the parameters. This means that all files contribute \n",
    "two points less to the algorythm, hence why two point files are useless for training. If uncertainty is used the parameters will have an uncertainty assigned to each of them. In \n",
    "order for the model to avoid treating the uncertainties as independent values (when they are dependent to only one of them) we are removing them entirely. Technically the algorythm \n",
    "is able to determine if the parameters are useful and reduce the weight to them. As we have so few points, in case this weighting is not done correctly, I have decided to ignore them\n",
    "Warning, the outputs are scaled (if you want them raw you will have to undo this scaling). Everything has been taken care of automatically\n",
    " Summary of Options\n",
    "Option\tDescription\n",
    "1. Leave as is\tFirst/last points removed from time series, added to static params. No duplication. <- What we are doing\n",
    "2. Duplicate\tFirst/last points added to static, and remain in the time series. Duplicated info.\n",
    "3. Perturb\tFirst/last points added to static, and perturbed copies remain in time series.\n",
    "\n",
    " Option 1 – Leave as is (No duplication)\n",
    "    What you do: First and last (time, polarization) points are removed from the time series and used only as static parameters.\n",
    "    Pros:\n",
    "        No risk of information leakage from duplication.\n",
    "        Keeps static and dynamic features clearly separated.\n",
    "        Avoids overfitting to repeated values.\n",
    "        Cleanest conceptually.\n",
    "    Cons:\n",
    "        You're losing two data points per experiment — which may be relevant if datasets are small.\n",
    "        Time series now has a gap at beginning and end.\n",
    "        Might miss important boundary dynamics if those edges are meaningful (e.g. stabilization or edge effects).\n",
    " Best if you want a clean and leak-proof setup and you're okay with slightly reduced data volume.\n",
    " Option 2 – Duplicate first/last into both static and time series\n",
    "    What you do: First and last values are added to static vector and remain in the time series.\n",
    "    Pros:\n",
    "        You retain all original data points, no loss in dataset size.\n",
    "        You still have access to boundary behavior through static features.\n",
    "        Easier to debug/troubleshoot models if you see consistency across static/dynamic behavior.\n",
    "    Cons:\n",
    "        Information leakage: same value appears in two places, and each is scaled separately.\n",
    "        Risk of overfitting, especially if those boundary values dominate or are strongly correlated with labels.\n",
    "        Can confuse models trained to learn relationships, if they see one value in two places with different scaling.\n",
    "        Scaling separately can make the model learn inconsistent representations of the same quantity.\n",
    " Only choose this if your data is scarce and overfitting isn’t a concern, or if the duplicates are negligible in impact.\n",
    " Option 3 – Perturb duplicates\n",
    "    What you do: First/last are added to static vector, and a slightly altered copy remains in the time series (e.g. polarization adjusted using Gaussian noise via uncertainty, small delta on time).\n",
    "    Pros:\n",
    "        Keeps all data points, like Option 2.\n",
    "        Reduces leakage risk because values are no longer exactly the same.\n",
    "        Still captures edge dynamics in the time series.\n",
    "        Adds small noise robustness to the model.\n",
    "    Cons:\n",
    "        Still not completely clean — the model may still learn the similarity between static and perturbed values.\n",
    "        If not carefully tuned, noise could introduce label mismatch or make the data noisier than real measurements.\n",
    "        Slightly more complex to implement and explain.\n",
    "        You now have synthetic data in your real dataset, which might affect interpretability.\n",
    " This is a clever compromise, especially if:\n",
    "    You're worried about data size,\n",
    "    You want to retain edge info,\n",
    "    And you don’t want outright duplication.\n",
    "Just make sure the noise scale matches real uncertainty — otherwise you risk corrupting the training signal.\n",
    " Final Recommendation\n",
    "    If you value clean data splits and minimizing information leakage, go with Option 1.\n",
    "    If you need every datapoint and the duplicates are unlikely to skew things, Option 2 is easier but riskier.\n",
    "    If you want a smart middle ground with some noise robustness, Option 3 is the most nuanced but effective — just be careful with your noise scale.\n",
    "\n",
    "That way the static vector (with initial and final points included), the polarizations and the time are scaled independently and the scaler is obtained using all but the isolated experiment (to avoid information leakage)\n",
    "\n",
    "5. Augment the experiments used for training. Augmentation of experiments is the process by which we use the uncertainty of the points of our experiment to create \"fake experiments\" which could have been measured. Knowing a measurement with uncertainty can be interpreted statistically as a probability of measuring a value inside the error bars. If we were to measure again the same point it is probable that the result would be different (but inside the uncertainty range). Therefore another experiment where our measurements are slightly different but inside the error margins is as valid as our original one. This way we can create copies of the experiment increasing the number of points the ML algorythm can learn from. \n",
    "There is one disadvantage of doing augmentation and that is that if the data is augmented too many times, the algorithm will always overfit (5-10 is said to be ok but better safe than sorry). Augment each experiment by adding Gaussian noise to polarization using uncertainty. Returns combined list of original + augmented experiments.\n",
    "\n",
    "6. Train the model with all experiments but the isolated one and save the scalers and model. The model uses the uncertainty ONLY during augmentation.\n",
    "\n",
    "7. Prepare the isolated experiment and obtain the linear correction. As our upmost priority is to obtain a prediction capable of substituting the experimental process, i.e. the ML prediction is not the be-all and end-all, an automatic correction is calculated. The first and final points are known so it makes sense that our final curve needs to pass through those two points. Therefore the pure ML prediction will get a linear curve substracted so that these two points are fitted perfectly. It can be toggled on or off\n",
    "\n",
    "8. Use the trained model to predict (with or without the correction) and store all the possible important information\n",
    "\n",
    "9. Return the isolated experiment and repeat the process\n",
    "\n",
    "10. Repeat the process for all four models currently available (you can add new ones by creating a new one on Define_Complexity and adding it to the list on the 'for Complexity' loop) and the four number of augmentations [\"Naif\", \"Simple\", \"Average\",\"Complex\"], [3,5,7,9]\n",
    "\n",
    "11. The time it takes is also recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633981cf-b021-4125-b6dd-3ac758d8bc90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, regularizers\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import shutil\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, regularizers\n",
    "from tensorflow.keras.layers import Dense, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import shutil\n",
    "import gc\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "def win_long_path(path: str) -> str:\n",
    "    path = os.path.abspath(path)  # normalize to absolute, resolves \"..\"\n",
    "    if os.name == \"nt\":  # only on Windows\n",
    "        if not path.startswith(\"\\\\\\\\?\\\\\"):\n",
    "            path = \"\\\\\\\\?\\\\\" + path\n",
    "    return path\n",
    "\"\"\"\n",
    "When loading a single experiment and Hot-encoding CellID the program won't know it it should encode one or three values. (brings up an error of shape mismatch)\n",
    "WARNING VERY VERY IMPORTANT, IF A NEW CELL IS ADDED, TWO EXPERIMENTS WITH THAT CELL ARE REQUIRED OR HOT ENCODING WILL BREAK (AND THE PROGRAM WON'T PREDICT WITH ZERO EXAMPLES OF THAT CELL)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "THIS IS NOT A MODEL CREATING CODE. IT IS A TESTING CODE. This algorythm trains models with all but one experiment and then tries to predict on this one. If we try to predict on an\n",
    "experiment that has been used for training or validation the result will most likey just be a memorization of the data. By removing the experiment before training we make sure that\n",
    "the predictions are made on an experiment that the algorythm has never seen. Using the laptops of the ILL the entire code takes between 11000 seconds to 27000 seconds. If you need \n",
    "to run it, leave it overnight. \n",
    "\n",
    "Why should I use this code?\n",
    "Once enough data files are present on the database it might be needed to remove the linear correction or the model will have to be made simpler or more complex. With this code you can \n",
    "test yourself if the model is correct or if it needs corrections\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "1. LOG MESSAGE AND GENERAL VARIABLES\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Message logging is done like in FileLecture. Here you cn also toggle if log_messages are shown, if plots are shown, if uncertainty is used for the loss function and to augment the experiments\n",
    "\"\"\"\n",
    "# You can toggle what model to use here\n",
    "# model_type = \"kerasDrop\"\n",
    "model_type = \"Conv1D\"\n",
    "\n",
    "PrintDebug = False #This Bool will determine if all logs should be log_messageed on screen on the Python Notebook. The log writing is always on. If False the code will be faster.\n",
    "ShowPlot = False #This Bool works the same but with showing on screen the plots (they are always saved even with this variable being False). Reduces program cost if False\n",
    "LogNoise = False #This Bool allows numerical values in the log. Most of these values are not worth keeping but if you want to see if there are no NaNs or zeros you can turn it on\n",
    "\n",
    "log_file_path = \"CrystallineLog_Testing_ML.txt\"\n",
    "# Initialize log file at the start of the script\n",
    "with open(log_file_path, 'w', encoding='utf-8') as log_file:\n",
    "    log_file.write(\"=== Log started ===\\n\")\n",
    "\n",
    "def log_message(message):\n",
    "    if PrintDebug:\n",
    "        print(message)\n",
    "    with open(log_file_path, 'a', encoding='utf-8') as log_file:\n",
    "        log_file.write(message + \"\\n\")\n",
    "to_erase = [\"CrystallineExecution_times.txt\", \"CrystallineLog_Testing_ML.txt\"]\n",
    "for item in to_erase:\n",
    "    path = os.path.abspath(item)  # full path\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            if os.path.isfile(path):\n",
    "                os.remove(path)\n",
    "                log_message(f\"Deleted file: {path}\")\n",
    "            elif os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "                log_message(f\"Deleted folder: {path}\")\n",
    "        except Exception as e:\n",
    "            log_message(f\" Could not delete {path}: {e}\")\n",
    "    else:\n",
    "        log_message(f\"Not found (skipped): {path}\")\n",
    "\"\"\"\n",
    "1. LOAD ALL EXPERIMENTS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Just receives the direction of the folder where all experiments reside, the name of the column that will be used (PolarizationD3 or SoftPolarizationD3) and if it should use uncertainy or not.\n",
    "Uncertainty will be used in the data to augmentate it (create copies of the experiments with values slightly different using a gaussian interpretation of the uncertainty). However if use_uncertainty is off \n",
    "then uncertainties won't be used when fitting or predciting and the outputs won't have uncertainty. \n",
    "Pros of uncertainty are better predictions\n",
    "Cons of uncertainty are slower time and more complex methods (risk of overfitting)\n",
    "This code will extract all the data and store the information as a tuple of Static_parameters(hot encoded), DeltaTime, Polarization (the column chosen) and a column for uncertainty\n",
    "\"\"\"\n",
    "def load_all_experiments(data_dir, polarization_column):\n",
    "    log_message(f\"Finding all Array Files...\")\n",
    "    arrays_files = sorted(\n",
    "        glob.glob(os.path.join(data_dir, \"*.txt\"))) #Find all files that are .txt\n",
    "    arrays_files = [f for f in arrays_files if not f.endswith(\"_Parameters.txt\")] #Keep only the Arrays (not the parameters) (we are only working with the names!)\n",
    "\n",
    "    encoded_experiments = []\n",
    "    all_static_df = []\n",
    "\n",
    "    static_columns = ['CellID', 'Pressure', 'LabPolarization', 'LabTime'] #Parameter header\n",
    "\n",
    "    for arrays_path in arrays_files:\n",
    "        base = os.path.basename(arrays_path)\n",
    "        # Build parameters filename by adding _Parameters before .txt\n",
    "        name_without_ext = os.path.splitext(base)[0]\n",
    "        parameters_filename = f\"{name_without_ext}_Parameters.txt\"\n",
    "        parameters_path = os.path.join(data_dir, parameters_filename)\n",
    "\n",
    "        # Read parameters file\n",
    "        try:\n",
    "            parameters_df = pd.read_csv(parameters_path) #Import the parameter file\n",
    "            if LogNoise:\n",
    "                log_message(f\"Reading parameters file: {parameters_filename}\") #Clutter logging\n",
    "\n",
    "            # get the second row (actually first data row, index 0) as static data\n",
    "            static_row = parameters_df.iloc[0][static_columns] #Get the parameter numerical values\n",
    "            all_static_df.append(static_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            log_message(f\"Failed to read parameters file: {parameters_filename}, error: {e}\")\n",
    "            continue\n",
    "\n",
    "    log_message(f\"Create combined DataFrame for static parameters...\")\n",
    "    static_df = pd.DataFrame(all_static_df) #Combine all static rows into a Dataframe\n",
    "\n",
    "    log_message(f\"Collected static data:\")\n",
    "    \"\"\"\n",
    "    Planned visit to see the polariser cells. To have something Hot enconded means that they are changing strings into binary columns (for example, CellID=A, B or C becomes A==[1,0,0], B==[0,1,0], C==[0,0,1]).\n",
    "    Eventually we will change it so the CellID is exchanged with more information about the cells but it is not the top priority\n",
    "    \"\"\"\n",
    "    log_message(f\"Hot encoding CellID PLACEHOLDER, VISIT TO THE LAB MAY BE NEEDED\") \n",
    "    categorical_cols = ['CellID']\n",
    "    static_df = pd.get_dummies(static_df, columns=categorical_cols) #Does the hot encoding\n",
    "    \n",
    "    # Now second pass: read arrays and create encoded_experiments with encoded static params\n",
    "    for i, arrays_path in enumerate(arrays_files):\n",
    "        base = os.path.basename(arrays_path)\n",
    "        name_without_ext = os.path.splitext(base)[0]\n",
    "        parameters_filename = f\"{name_without_ext}_Parameters.txt\"\n",
    "        parameters_path = os.path.join(data_dir, parameters_filename)\n",
    "        # log_message(f\"Reading arrays file: {base}\") #Clutter log\n",
    "        arrays_df = pd.read_csv(arrays_path) # Reads the time series data \n",
    "    \n",
    "        static_values = static_df.iloc[i].to_list() #Fetches the static parameters corresponding to this experiment\n",
    "    \n",
    "        Deltatime = arrays_df[\"DeltaTime\"].values\n",
    "        polarization = arrays_df[polarization_column].values #Extracts the time array and the selected polarization column.\n",
    "        #Save the uncertainty even if it is not used afterwards\n",
    "        Uncertainty = arrays_df[\"ErrPolarizationD3\"].values\n",
    "        #if len(Deltatime) > 2:\n",
    "        encoded_experiments.append((static_values, Deltatime, polarization, Uncertainty))\n",
    "        # log_message(f\"Creating Encoded Experiments (appending parameters, time array, polarization array and uncertainty array)\") #Clutter log\n",
    "    log_message(f\"Loaded {len(encoded_experiments)} experiments.\")\n",
    "    return encoded_experiments, static_df.columns.tolist()\n",
    "\n",
    "\"\"\"\n",
    "2. AUGMENT EXPERIMENTS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Augmentation of experiments is the process by which we use the uncertainty of the points of our experiment to create \"fake experiments\" which could have been measured\n",
    "Knowing a measurement with uncertainty can be interpreted estadisticaly as a probability of measuring a value inside the error bars. If we were to measure again the same point\n",
    "it is propable that the result would be different (but inside the uncertainty range). Therefore another experiment where our measurements are slightly different but inside the \n",
    "error margins is as valid as our original one. This way we can create copies of the experiment increasing the number of points the ML algorythm can learn from.\n",
    "There is one disadvantage of doing augmentation and that is that if the data is augmented too many times, the algorythm will always overfit (5-10 is said to be ok but better safe than sorry)\n",
    "Augment each experiment by adding Gaussian noise to polarization using uncertainty.\n",
    "Returns combined list of original + augmented experiments.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def augment_experiments(original_experiments, num_augmentations=5, base_seed=42):\n",
    "    log_message(f\"Augmenting {len(original_experiments)} a number of {num_augmentations} times\")\n",
    "    augmented_experiments = []\n",
    "    for idx, (static, time, polar, uncertainty) in enumerate(original_experiments):\n",
    "        for n in range(num_augmentations):\n",
    "            seed = hash((idx, n, base_seed)) % 2**32\n",
    "            rng = np.random.default_rng(seed)\n",
    "            noise = rng.normal(loc=0.0, scale=uncertainty)\n",
    "            new_polar = polar + noise\n",
    "            if LogNoise:\n",
    "                log_message(f\"      Augmented experiment {idx} #{n} with seed {seed}\")\n",
    "            augmented_experiments.append((static, time, new_polar, uncertainty))\n",
    "    log_message(f\"Augmented to {len(original_experiments + augmented_experiments)} experiments\")\n",
    "    return original_experiments + augmented_experiments\n",
    "\n",
    "\"\"\"\n",
    "3. BUILD DATASET (FINAL MODIFICATION TO THE STRUCTURE OF THE DATA)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "When this algorythm is used, we will give it the same parameter types and the beginning and final polarization. Therefore the wisest approach is to teach the model with this\n",
    "exact structure. Therefore it is needed that we extract the initial and final polarization from the files and add it into the parameters. This means that all files contribute \n",
    "two points less to the algorythm, hence why two point files are useless for training. If uncertainty is used the parameters will have an uncertainty assigned to each of them. In \n",
    "order for the model to avoid treating the uncertainties as independent values (when they are dependent to only one of them) we are removing them entirely. Technically the algorythm \n",
    "is able to determine if the parameters are useful and reduce the weight to them. As we have so few points, in case this weighting is not done correctly, I have decided to ignore them\n",
    "Warning, the outputs are scaled (if you want them raw you will have to undo this scaling). Eveything has been taken care of\n",
    " Summary of Options\n",
    "Option\tDescription\n",
    "1. Leave as is\tFirst/last points removed from time series, added to static params. No duplication. <- What we are doing\n",
    "2. Duplicate\tFirst/last points added to static, and remain in the time series. Duplicated info.\n",
    "3. Perturb\tFirst/last points added to static, and perturbed copies remain in time series.\n",
    "\n",
    " Option 1 – Leave as is (No duplication)\n",
    "    What you do: First and last (time, polarization) points are removed from the time series and used only as static parameters.\n",
    "    Pros:\n",
    "        No risk of information leakage from duplication.\n",
    "        Keeps static and dynamic features clearly separated.\n",
    "        Avoids overfitting to repeated values.\n",
    "        Cleanest conceptually.\n",
    "    Cons:\n",
    "        You're losing two data points per experiment — which may be relevant if datasets are small.\n",
    "        Time series now has a gap at beginning and end.\n",
    "        Might miss important boundary dynamics if those edges are meaningful (e.g. stabilization or edge effects).\n",
    " Best if you want a clean and leak-proof setup and you're okay with slightly reduced data volume.\n",
    " Option 2 – Duplicate first/last into both static and time series\n",
    "    What you do: First and last values are added to static vector and remain in the time series.\n",
    "    Pros:\n",
    "        You retain all original data points, no loss in dataset size.\n",
    "        You still have access to boundary behavior through static features.\n",
    "        Easier to debug/troubleshoot models if you see consistency across static/dynamic behavior.\n",
    "    Cons:\n",
    "        Information leakage: same value appears in two places, and each is scaled separately.\n",
    "        Risk of overfitting, especially if those boundary values dominate or are strongly correlated with labels.\n",
    "        Can confuse models trained to learn relationships, if they see one value in two places with different scaling.\n",
    "        Scaling separately can make the model learn inconsistent representations of the same quantity.\n",
    " Only choose this if your data is scarce and overfitting isn’t a concern, or if the duplicates are negligible in impact.\n",
    " Option 3 – Perturb duplicates\n",
    "    What you do: First/last are added to static vector, and a slightly altered copy remains in the time series (e.g. polarization adjusted using Gaussian noise via uncertainty, small delta on time).\n",
    "    Pros:\n",
    "        Keeps all data points, like Option 2.\n",
    "        Reduces leakage risk because values are no longer exactly the same.\n",
    "        Still captures edge dynamics in the time series.\n",
    "        Adds small noise robustness to the model.\n",
    "    Cons:\n",
    "        Still not completely clean — the model may still learn the similarity between static and perturbed values.\n",
    "        If not carefully tuned, noise could introduce label mismatch or make the data noisier than real measurements.\n",
    "        Slightly more complex to implement and explain.\n",
    "        You now have synthetic data in your real dataset, which might affect interpretability.\n",
    " This is a clever compromise, especially if:\n",
    "    You're worried about data size,\n",
    "    You want to retain edge info,\n",
    "    And you don’t want outright duplication.\n",
    "Just make sure the noise scale matches real uncertainty — otherwise you risk corrupting the training signal.\n",
    " Final Recommendation\n",
    "    If you value clean data splits and minimizing information leakage, go with Option 1.\n",
    "    If you need every datapoint and the duplicates are unlikely to skew things, Option 2 is easier but riskier.\n",
    "    If you want a smart middle ground with some noise robustness, Option 3 is the most nuanced but effective — just be careful with your noise scale.\n",
    "\"\"\"\n",
    "def build_dataset(experiments, mode=\"PolarizationD3\"):\n",
    "\n",
    "    Xs, Xt, y, u = [], [], [], []\n",
    "    log_message(f\"Starting build_dataset for column {mode} \")\n",
    "    log_message(f\"Number of experiments to process: {len(experiments)} (should be (num_augmentations+1)*(number_of_experiments-1)\")\n",
    "    \n",
    "    for exp_idx, (static_params, delta_time, polarization, uncertainty) in enumerate(experiments):\n",
    "        if len(delta_time) < 2:\n",
    "            log_message(f\"Skipping experiment {exp_idx}: too few data points (len={len(delta_time)})\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if LogNoise:\n",
    "            log_message(f\"      Adding First and Last Polarization (with time) values as static parameters\") #Clutter log\n",
    "        init_idx = 0\n",
    "        final_idx = -1\n",
    "        initial_dt, initial_p = delta_time[init_idx], polarization[init_idx]\n",
    "        final_dt, final_p = delta_time[final_idx], polarization[final_idx]\n",
    "\n",
    "        static_vector = static_params + [\n",
    "            initial_dt, initial_p,\n",
    "            final_dt, final_p\n",
    "        ]\n",
    "        if LogNoise:\n",
    "            log_message(f\"      Experiment {exp_idx}: static_vector length={len(static_vector)} (should be 10 (three parameters, CellID hot encoded creates three posibilities, four for the initial and final polarization) \") #Clutter log\n",
    "        if LogNoise:\n",
    "            log_message(f\"      Building samples Static+time+polarization\") #Clutter log\n",
    "        \n",
    "        #Ignoring first and last points, creates the four arrays of experiments. The n-th component of these lists will have, respectively, the static-vector of the n-th experiment,\n",
    "        #the whole time list of the n-th experiment, the whole polarization column (chosen with the mode) and the entire uncertainty array.\n",
    "        for t, p, err in zip(delta_time[1:-1], polarization[1:-1], uncertainty[1:-1]): \n",
    "            Xs.append(static_vector)\n",
    "            Xt.append([t])\n",
    "            y.append(p)\n",
    "            u.append(err) #We will ignore always uncertainty in parameters and even if they are not used, we will keep uncertainties in the data sets(same dimensions everywhere)\n",
    "\n",
    "    log_message(f\"Number of experiments processed for mode '{mode}': {len(experiments)}\")\n",
    "    log_message(f\"Final dataset shapes: Xs: {np.array(Xs).shape}, Xt: {np.array(Xt).shape}, y: {np.array(y).reshape(-1, 1).shape}\")\n",
    "    return np.array(Xs), np.array(Xt), np.array(y).reshape(-1, 1), np.array(u).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5. LOSS FUNCTION\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "ML algorythms require a way to tell the algorythm if it is learning or not. The most standard practice is with a Loss function. If the loss value goes down that means that the\n",
    "algorythm is learning and if a step it does increases loss then it is punished and tries other things. When using uncertainties when teaching the model, the most common loss \n",
    "function is the NLL or Negative log-likelihood of a normal distribution NLL=\\frac{1}{2}log(σ^2)+\\frac{(y−μ)^2}{2σ^2}. Instead of predicting σ^2 we obtain its logarythm to \n",
    "have a more stable process.\n",
    "\"\"\"\n",
    "def nll_loss(y_true, y_pred):\n",
    "    mu = y_pred[:, 0:1]\n",
    "    log_var = y_pred[:, 1:2]\n",
    "    precision = K.exp(-log_var)\n",
    "    return K.mean(0.5 * (log_var + K.square(y_true - mu) * precision))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "6. MODEL ARCHITECTURE\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Keras with tensorflow and only dense layers has proven to be too complex for a data base of less than 1000 points. After converting the experiments with build_database, only ~720 points are used for\n",
    "training and validation. Therefore I have implemented a if-toggle to switch from different types of models. The only model-type dependent parts of the whole pipeline are the\n",
    "building of the model, the predictions with the model and fitting with the model. Functions have been created for all of them so that (despite being functions with one line of code\n",
    "only) it is easier to toggle from one model to the other.\n",
    "\n",
    "build_model builds the model (obviously)\n",
    "model_fitting will learn from the input targets nad predict and validates (compares) with the target values (y_values in keras) (changing the weights using backpropagation).\n",
    "Model predicting won't train or validate, it will just predict. NOrmally only requests the parameters and the times where we will predict. You must imput the model (it is not created in situ)\n",
    "\"\"\"\n",
    "\n",
    "model_type = \"Conv1D\"\n",
    "\"\"\"\n",
    "Using Conv1D we emphasize more on the time evolution of the data. This is really good in our case as we don't need abstract connections (with dense layers) and we are more\n",
    "interested on dependencies with time. There is no model that is better than the rest. If the model is too complex, overfitting will occur and we will have a useless model. If \n",
    "it is complex but not too much then the algoryhtm will start finding patterns that may or may not have real meaning (like oscillations). We truly don't have a good way to \n",
    "say if these structures are spurious or not. However if the model is too simple it will just output linear predictions. Given the structure and scale of our patterns this\n",
    "predictions are not necessarily bad but they are not the best. The real prove that is works will be tring to correct the real data\n",
    "\"\"\"\n",
    "def Define_Complexity(Complexity):\n",
    "    from tensorflow.keras import Input, Model, regularizers\n",
    "    from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense, Dropout, Concatenate\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    if Complexity == \"Average\":       \n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "\n",
    "    elif Complexity == \"Complex\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.3)(x_time)\n",
    "            x_time = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = Dropout(0.3)(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(16, activation='tanh')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "\n",
    "    elif Complexity == \"Simple\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.3)(x_time)\n",
    "            x_time = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-2))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "\n",
    "    elif Complexity == \"Naif\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif834\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif838\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif8316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif8332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif854\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif858\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif8516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif8532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif8104\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif8108\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif81016\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif81032\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    elif Complexity == \"Naif1634\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif1638\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif16316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif16332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif1654\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif1658\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif16516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif16532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif16104\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif16108\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif161016\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif161032\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    elif Complexity == \"Naif2434\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif2438\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif24316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif24332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif2454\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif2458\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif24516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif24532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif24104\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif24108\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "    elif Complexity == \"Naif241016\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model        \n",
    "    elif Complexity == \"Naif241032\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=24, kernel_size=10, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='relu')(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            if use_uncertainty:\n",
    "                log_var = Dense(1)(x)\n",
    "                output = Concatenate()([mu, log_var])\n",
    "            else:\n",
    "                output = mu\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"NaifTwice1D883316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D883332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D883516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D883532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwice1D885316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D885332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D885516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D885532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwice1D843316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D843332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D843516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D843532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwice1D845316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D845332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D845516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D845532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"NaifTwice1D483316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D483332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D483516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D483532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwice1D485316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D485332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D485516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D485532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwice1D443316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D443332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D443516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D443532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwice1D445316\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D445332\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"NaifTwice1D445516\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"NaifTwice1D445532\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=5, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"NaifTwiceDense414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model                    \n",
    "    elif Complexity == \"NaifTwiceDense4116\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense4124\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense8116\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense8124\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense1614\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense1618\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense16116\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense16124\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense2414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense2418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense24116\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense24124\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"NaifTwiceDense424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model                    \n",
    "    elif Complexity == \"NaifTwiceDense4216\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense4224\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense8216\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense8224\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense1624\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model    \n",
    "    elif Complexity == \"NaifTwiceDense1628\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense16216\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense16224\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(16, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense2424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense2428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense24216\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(16, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"NaifTwiceDense24224\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(24, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)   # moved here\n",
    "            x = Dense(24, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"SimpleNoDropout444\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"SimpleNoDropout448\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "        \n",
    "    elif Complexity == \"SimpleNoDropout484\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout488\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout4164\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout4168\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "\n",
    "    elif Complexity == \"SimpleNoDropout844\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"SimpleNoDropout848\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"SimpleNoDropout884\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout888\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout8164\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout8168\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model         \n",
    "    elif Complexity == \"SimpleNoDropout1644\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model            \n",
    "    elif Complexity == \"SimpleNoDropout1648\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model  \n",
    "    elif Complexity == \"SimpleNoDropout1684\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout1688\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout16164\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model          \n",
    "    elif Complexity == \"SimpleNoDropout16168\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model         \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"Simple414414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple414418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple414424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple414428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple414814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple414818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple414824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple414828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model                 \n",
    "    elif Complexity == \"Simple418414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple418418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple418424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple418428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple418814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple418818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple418824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple418828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model   \n",
    "    elif Complexity == \"Simple424414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple424418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple424424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple424428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple424814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple424818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple424824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple424828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model                 \n",
    "    elif Complexity == \"Simple428414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple428418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple428424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple428428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple428814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple428818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple428824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple428828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    elif Complexity == \"Simple814414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple814418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple814424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple814428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple814814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple814818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple814824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple814828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model                 \n",
    "    elif Complexity == \"Simple818414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple818418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple818424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple818428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple818814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple818818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple818824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple818828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.1)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model   \n",
    "    elif Complexity == \"Simple824414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple824418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple824424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple824428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple824814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple824818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple824824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple824828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=4, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model                 \n",
    "    elif Complexity == \"Simple828414\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple828418\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple828424\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple828428\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(4, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "        \n",
    "    elif Complexity == \"Simple828814\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple828818\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model \n",
    "    elif Complexity == \"Simple828824\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x)\n",
    "            x = Dense(4, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model             \n",
    "    elif Complexity == \"Simple828828\":\n",
    "        def build_model(input_dim_static, use_uncertainty=False):\n",
    "            static_input = Input(shape=(input_dim_static,), name=\"static_input\")\n",
    "            time_input = Input(shape=(None, 1), name=\"time_input\")\n",
    "\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(time_input)\n",
    "            x_time = Dropout(0.2)(x_time)\n",
    "            x_time = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same')(x_time)\n",
    "            x_time = GlobalAveragePooling1D()(x_time)\n",
    "\n",
    "            x = Concatenate()([static_input, x_time])\n",
    "            x = Dense(8, activation='tanh', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "            x = Dropout(0.2)(x_time)\n",
    "            x = Dense(8, activation='tanh')(x)  # second dense layer\n",
    "\n",
    "            mu = Dense(1)(x)\n",
    "            log_var = Dense(1)(x)\n",
    "            output = Concatenate()([mu, log_var])\n",
    "\n",
    "            model = Model(inputs=[static_input, time_input], outputs=output)\n",
    "            model.compile(optimizer=Adam(), loss=nll_loss if use_uncertainty else 'mse')\n",
    "            return model         \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    log_message(f\"Built model {Complexity}\")\n",
    "    return build_model  # <--- IMPORTANT\n",
    "\n",
    "                \n",
    "          \n",
    "        \n",
    "def model_fitting(model, X_static_scaled, X_time_scaled, y_scaled, epochs, batch_size, verbose, callbacks=None):\n",
    "    log_message(f\"Training the model...\")\n",
    "    return model.fit(\n",
    "        [X_static_scaled, X_time_scaled],\n",
    "        y_scaled,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=verbose,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "def model_prediction(model, X_static_scaled, X_time_scaled):\n",
    "    log_message(f\"Predicting {len(X_time_scaled)} time points\")\n",
    "    return model.predict([X_static_scaled, X_time_scaled], verbose=0)\n",
    "        \n",
    "\"\"\"\n",
    "7. PLOT EXPERIMENTS \n",
    "\"\"\"\n",
    "\"\"\"\n",
    "This function is currently not being used\n",
    "Just a quick check to see if there is no underfitting. The bare minimum the ML algorythm should be able to do is to predict the data points it learned from training and validation\n",
    "There is no differnece when plotting if uncertainty is on or off, the changes are only on the model that is being imported\n",
    "Will plot the experiments you give it (if you only give one, it will only do one, if you give it all but one, then all but one will be plotted)\n",
    "\n",
    "\n",
    "def plot_experiments(encoded_experiments, scaler_static, scaler_time, scaler_y, model_type, model, output_folder, base_name, use_uncertainty=False, mode='PolarizationD3', N_offset=0.0):\n",
    "    log_message(f\"Begin Plotting...\")\n",
    "    total_exps = len(encoded_experiments)\n",
    "    colors = plt.colormaps.get_cmap('tab20').resampled(total_exps)\n",
    "\n",
    "\n",
    "\n",
    "    for exp_idx, exp in enumerate(encoded_experiments):\n",
    "        static_params, delta_time, true_polar, real_uncertainty = exp\n",
    "        initial_dt, initial_p = delta_time[0], true_polar[0]\n",
    "        final_dt, final_p = delta_time[-1], true_polar[-1]\n",
    "        static_vector = static_params + [initial_dt, initial_p, final_dt, final_p]\n",
    "\n",
    "\n",
    "        color = colors(exp_idx)\n",
    "        grid_times = np.arange(0, max(delta_time) + 1000, 1000)\n",
    "        static_array = np.tile(static_vector, (len(grid_times), 1))\n",
    "        time_array = grid_times.reshape(-1, 1)\n",
    "    \n",
    "        static_scaled = scaler_static.transform(static_array)\n",
    "        time_scaled = scaler_time.transform(time_array)\n",
    "    \n",
    "        if model_type == 'kerasDrop':\n",
    "            pred_scaled = model_prediction(model, static_scaled, time_scaled)\n",
    "        if model_type == 'Conv1D':\n",
    "            pred_scaled = model_prediction(model, static_scaled, time_scaled)\n",
    "            \n",
    "        mu_pred = scaler_y.inverse_transform(pred_scaled[:, 0:1])\n",
    "        mu_pred -= N_offset #Correction in the y-axis\n",
    "\n",
    "        sigma = np.sqrt(np.exp(pred_scaled[:, 1:2])) * (mu_pred + 1e-6)\n",
    "    \n",
    "        # Common suffix and base name\n",
    "        suffix = \"_uncertainty\" if use_uncertainty else \"_no_uncertainty\"\n",
    "        base_title = f\"Experiment {exp_idx + 1}, column={mode}, {base_name}\"\n",
    "    \n",
    "        def make_plot(tight=False):\n",
    "            fig, ax = plt.subplots(figsize=(8, 5)) \n",
    "            title = f\"Experiment_{exp_idx + 1}{suffix}_{mode}_Missing{base_name}.png\" + (\" — tight\" if tight else \"\")\n",
    "            ax.set_title(title)\n",
    "            ax.grid(True)\n",
    "    \n",
    "            ax.scatter(delta_time, true_polar, color=color, marker='o', s=40, label=\"True\")\n",
    "            ax.errorbar(delta_time, true_polar, yerr=real_uncertainty, fmt='none',\n",
    "                        ecolor=color, alpha=0.6, capsize=3, label=\"Real ±σ\")\n",
    "            ax.scatter(grid_times, mu_pred, color=color, marker='x', s=40, label=\"Pred Points\")\n",
    "            ax.plot(grid_times, mu_pred, '--', color=color, alpha=0.7, label=\"Pred Line\")\n",
    "            ax.fill_between(grid_times, (mu_pred - sigma).flatten(), (mu_pred + sigma).flatten(),\n",
    "                            color=color, alpha=0.2, label=\"Predicted ±1σ\")\n",
    "    \n",
    "            if tight:\n",
    "                y_min = min(np.min(true_polar), np.min(mu_pred))-0.05\n",
    "                y_max = max(np.max(true_polar), np.max(mu_pred))+0.05\n",
    "                ax.set_ylim([y_min, y_max])\n",
    "    \n",
    "            ax.legend()\n",
    "            fig.tight_layout()\n",
    "    \n",
    "            # Save figure\n",
    "            tight_str = \"_tight\" if tight else \"\"\n",
    "            fig_filename = f\"Experiment_{exp_idx + 1}{suffix}_{mode}{tight_str}_Missing{base_name}.png\"\n",
    "            fig_path = output_folder / fig_filename\n",
    "            log_message(f\"Saved figure to: {fig_path}\")\n",
    "            fig.savefig(fig_path.with_suffix(\".jpg\"), dpi=100)\n",
    "            plt.close(fig)\n",
    "            del fig, ax\n",
    "            gc.collect()\n",
    "    \n",
    "        # Create both plots\n",
    "        make_plot(tight=False)  # original\n",
    "        make_plot(tight=True)   # tight version\n",
    "        # === Write RawData.txt ===\n",
    "        raw_data_path = output_folder / f\"RawData_{mode}_Missing{base_name}.txt\"\n",
    "        with open(raw_data_path, 'w') as f:\n",
    "            f.write(f\"DeltaTime\\tRealPolarizationD3\\tErrRealPolarizationD3\\n\")\n",
    "            for t, p, e in zip(delta_time, true_polar, real_uncertainty):\n",
    "                f.write(f\"{t:.6f}\\t{p:.6f}\\t{e:.6f}\\n\")\n",
    "        log_message(f\"Saved raw data to: {raw_data_path}\")\n",
    "\n",
    "        # === Write PredictedData.txt ===\n",
    "        predicted_data_path = output_folder / f\"PredictedData_{mode}_Missing{base_name}.txt\"\n",
    "        with open(predicted_data_path, 'w') as f:\n",
    "            f.write(f\"GridTime\\tPredictedPolarizationD3\\tErrPredictedPolarizationD3\\n\")\n",
    "            for t, p, s in zip(grid_times, mu_pred.flatten(), sigma.flatten()):\n",
    "                f.write(f\"{t:.6f}\\t{p:.6f}\\t{s:.6f}\\n\")\n",
    "        log_message(f\"Saved predicted data to: {predicted_data_path}\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The same as train_and_plot but without plotting\n",
    "\"\"\"\n",
    "def train(encoded_experiments, scaler_static, scaler_time, scaler_y, model_type, use_uncertainty, mode):\n",
    "    log_message(f\"Begin training and scaling with {len(encoded_experiments)} experiments.\")\n",
    "    X_static_all, X_time_all, y_all, u_all = build_dataset(encoded_experiments)\n",
    "\n",
    "\n",
    "    log_message(f\"Scaling all data\")\n",
    "    X_static_scaled = scaler_static.fit_transform(X_static_all)\n",
    "    X_time_scaled = scaler_time.fit_transform(X_time_all)\n",
    "    y_scaled = scaler_y.fit_transform(y_all)\n",
    "    \n",
    "    model = build_model(X_static_all.shape[1], use_uncertainty=use_uncertainty)\n",
    "    epochs = 300\n",
    "    batch_size = 32\n",
    "    log_message(f\"Training final model with epochs={epochs}, batch_size={batch_size} and use_uncertainty = {use_uncertainty}\")\n",
    "    model_fitting(model, X_static_scaled, X_time_scaled, y_scaled, epochs, batch_size, verbose=0)\n",
    "\n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "9. BUILD DATASET INCLUDING THE INITIAL AND FINAL POLARIZATION POINTS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Currently unused, does the same as build_dataset but doesn't extract the initial and final polarization to send them to the static vector. This way those values are scaled\n",
    "as regular polarization points and regular time points. Afterwards it adds them to the static parameters. Unused because we are scaling those four values as static parameters\n",
    "in the final build. (Will erase when project is finished)\n",
    "\"\"\"\n",
    "def build_dataset_including_edges(experiments, mode=\"PolarizationD3\"):\n",
    "    Xs, Xt, y, u = [], [], [], []\n",
    "    log_message(f\"      Starting build_dataset_including_edges for column {mode} \")\n",
    "    log_message(f\"      Number of experiments to process: {len(experiments)}\")\n",
    "    for exp_idx, (static_params, delta_time, polarization, uncertainty) in enumerate(experiments):\n",
    "        if len(delta_time) < 1:\n",
    "            log_message(f\"            Skipping experiment {exp_idx}: too few data points (len={len(delta_time)})\")\n",
    "            continue\n",
    "\n",
    "        for t, p, err in zip(delta_time, polarization, uncertainty):\n",
    "            static_vector = static_params + [delta_time[0], polarization[0], delta_time[-1], polarization[-1]]\n",
    "            if LogNoise:\n",
    "                log_message(f\"      Adding First and Last Polarization (with time) values as static parameters\")\n",
    "            Xs.append(static_vector)\n",
    "            Xt.append([t])\n",
    "            y.append(p)\n",
    "            u.append(err)\n",
    "        if LogNoise:\n",
    "            log_message(f\"      Experiment {exp_idx}: static_vector length={len(static_vector)} (should be 10 (three parameters, CellID hot encoded creates three posibilities, four for the initial and final polarization) \")\n",
    "        if LogNoise:\n",
    "            log_message(f\"      Building samples Static+time+polarization\")\n",
    "        log_message(f\"Number of experiments processed for mode '{mode}': {len(experiments)}\")\n",
    "        log_message(f\"Final dataset shapes: Xs: {np.array(Xs).shape}, Xt: {np.array(Xt).shape}, y: {np.array(y).reshape(-1, 1).shape}\")\n",
    "    return np.array(Xs), np.array(Xt), np.array(y).reshape(-1, 1), np.array(u).reshape(-1, 1)\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "def align_static_vectors(experiments, static_columns_training, static_columns_isolated):\n",
    "    aligned_experiments = []\n",
    "    for static, delta_time, polarization, uncertainty in experiments:\n",
    "        static_dict = dict(zip(static_columns_isolated, static))\n",
    "        aligned_static = [static_dict.get(col, 0.0) for col in static_columns_training]\n",
    "        aligned_experiments.append((aligned_static, delta_time, polarization, uncertainty))\n",
    "    return aligned_experiments\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "10. MODEL PREDICTIONS WITH FORCED INITIAL AND FINAL POLARIZATION PREDICTIONS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Some models don't predict the overall shape correctly. They find plateaus, abrupt slope changes but they have (normally) an overall slope that is not as steep as it should be. As a \n",
    "'discount' solution we can correct the predictions substracting a linear curve. The only points that we can use to correct the data are the first and final polarization values.\n",
    "By substracting the correct curve we can force the prediction for the initial and final point to be the experimental values. \n",
    "Is this method 'legal'? I don't know but at least we have something that makes sense and in a hurry you can get a better estimate. \n",
    "\n",
    "\"\"\"\n",
    "def model_predict_corrected(model, X_static_scaled, X_time_scaled, m, n, scaler_y, scaler_time):\n",
    "    log_message(f\"Correcting {len(X_time_scaled)} by subtracting P(t) = {float(np.squeeze(m)):.3e} * t + {float(np.squeeze(n)):.3e}\")\n",
    "    # Step 1: Get scaled predictions from model\n",
    "    # y_pred_scaled shape: (N, 2) --> columns: [mean_scaled, log_var_scaled]\n",
    "    y_pred_scaled = model_prediction(model, X_static_scaled, X_time_scaled)\n",
    "    \n",
    "    # Step 2: Inverse transform only the mean predictions to real units\n",
    "    mean_scaled = y_pred_scaled[:, 0:1]  # shape (N,1)\n",
    "    mean_real = scaler_y.inverse_transform(mean_scaled)  # shape (N,1)\n",
    "    \n",
    "    # Step 3: Inverse transform times to real units (for correction)\n",
    "    time_real = scaler_time.inverse_transform(X_time_scaled)  # shape (N,1)\n",
    "    \n",
    "    # Step 4: Calculate correction curve in real units\n",
    "    correction = m * time_real + n  # shape (N,1)\n",
    "    \n",
    "    # Step 5: Apply correction to mean predictions (real units)\n",
    "    mean_corrected_real = mean_real - correction  # shape (N,1)\n",
    "    \n",
    "    # Step 6: Scale corrected mean predictions back to scaled space\n",
    "    mean_corrected_scaled = scaler_y.transform(mean_corrected_real)  # shape (N,1)\n",
    "    \n",
    "    # Step 7: Keep log variance as is (no correction applied, shape (N,1))\n",
    "    log_var_scaled = y_pred_scaled[:, 1:2]  # shape (N,1)\n",
    "    \n",
    "    # Step 8: Recombine corrected mean and original log variance\n",
    "    y_pred_corrected_scaled = np.hstack([mean_corrected_scaled, log_var_scaled])  # shape (N,2)\n",
    "    \n",
    "    return y_pred_corrected_scaled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "11. MAIN CODE FUNCTION\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Extract one file, send to Isolated folder train with the rest, predict on the isolated one and repeat for all. Requires the model type, the direction with the data files. an outut folder\n",
    "name (to create the subfolders of each experiment in it), the number of augmentations to train the model with and finally a bool (Correction) to force the initial and final polarization\n",
    "predictions to be the measured values\n",
    "\"\"\"\n",
    "def isolate_experiments(data_dir,isolated_dir, model_type, output_folder, use_uncertainty, num_augmentations, Correction, build_model):\n",
    "    data_dir = Path(data_dir)\n",
    "    isolated_dir = Path(isolated_dir)\n",
    "    output_folder = Path(output_folder)\n",
    "\n",
    "    #1. Prepare the folder where the isolated experiments will reside\n",
    "    isolated_dir = data_dir.parent / \"CrystallineMLIsolatedExperiment\"\n",
    "    isolated_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Get all *_Parameters.txt files to derive base names\n",
    "    param_files = list(data_dir.glob(\"*_Parameters.txt\"))\n",
    "    base_names = [f.stem.replace(\"_Parameters\", \"\") for f in param_files]\n",
    "    for base_name in base_names:\n",
    "        file_param = data_dir / f\"{base_name}_Parameters.txt\"\n",
    "        file_data = data_dir / f\"{base_name}.txt\"\n",
    "\n",
    "        if not (file_param.exists() and file_data.exists()):\n",
    "            log_message(f\"Skipping {base_name}: One of the required files does not exist.\")\n",
    "            continue\n",
    "\n",
    "        # 3. Move both files to isolated folder\n",
    "        shutil.move(win_long_path(str(file_param)), win_long_path(str(isolated_dir / file_param.name)))\n",
    "        shutil.move(win_long_path(str(file_data)), win_long_path(str(isolated_dir / file_data.name)))\n",
    "\n",
    "        log_message(f\"Successfully sent {base_name} to {isolated_dir}\")\n",
    "\n",
    "        # 4. Create subfolder for this experiment\n",
    "        output_subfolder = output_folder / f\"Missing{base_name}\"\n",
    "        output_subfolder.mkdir(exist_ok=True)\n",
    "        log_message(f\"Created folder: {output_subfolder}\")\n",
    "\n",
    "        # 5. Train and predict using both modes\n",
    "        for mode in [\"PolarizationD3\"]: \n",
    "            log_message(f\"\\n=== Processing mode: {mode} (excluding {base_name}) ===\\n\")\n",
    "\n",
    "            # 6. Load all experiments and augment them\n",
    "            experiments, static_columns = load_all_experiments(str(data_dir), polarization_column=mode)\n",
    "            encoded_experiments = augment_experiments(experiments, num_augmentations, base_seed=42)\n",
    "\n",
    "            \n",
    "            #7. Scalers. All polarization and time values are scaled using all the experiments (except the isolated one). The reason for excluding them is to avoid information\n",
    "            #leackage. The static parameters are scaled afterwards but they are also scaled with all but one experiments\n",
    "            log_message(f\"Scale all experiments (except the isolated one)\")\n",
    "            all_time = []\n",
    "            all_y = []\n",
    "            \n",
    "            for static, time, pol, _ in encoded_experiments:\n",
    "                all_time.append(time)\n",
    "                all_y.append(pol)\n",
    "            \n",
    "            all_time = np.concatenate(all_time).reshape(-1, 1) #unscaled\n",
    "            all_y = np.concatenate(all_y).reshape(-1, 1) #unscaled\n",
    "            \n",
    "            scaler_time = MinMaxScaler().fit(all_time) #fit to all\n",
    "            scaler_y = MinMaxScaler().fit(all_y) #fit to all\n",
    "            \n",
    "            #8. Prepare all the experiments so that they can be introduced in the training functions\n",
    "            X_static_raw, X_time_raw, y_raw, u = build_dataset(encoded_experiments, mode=mode)\n",
    "            \"\"\" One might think to scale the polarization values using the polarization scaler and to scale the time values with the time scaler. However this comes with the\n",
    "            problem of having to juggle three scalers at once when working with the static vector. This proved to be difficult and showed no real improvement. If you scale those\n",
    "            values and then scale the entire vector (as it needs scaling) then you have values scaled twice that lose any links with the time and polarization scales. Therefore\n",
    "            it has been decided to just scale the entire vector using only the other static vectors\"\"\"\n",
    "            scaler_static = MinMaxScaler().fit(X_static_raw) #fit to all\n",
    "\n",
    "            if LogNoise:\n",
    "                log_message(f\"      Scaler static min_: , {scaler_static.min_}\")\n",
    "                log_message(f\"      Scaler static scale_: , {scaler_static.scale_}\")\n",
    "                log_message(f\"      Scaler static data_min_: , {scaler_static.data_min_}\")\n",
    "                log_message(f\"      Scaler static data_max_: , {scaler_static.data_max_}\")\n",
    "                \n",
    "                log_message(f\"      Scaler time min_: , {scaler_time.min_}\")\n",
    "                log_message(f\"      Scaler time scale_: , {scaler_time.scale_}\")\n",
    "                log_message(f\"      Scaler time data_min_: , {scaler_time.data_min_}\")\n",
    "                log_message(f\"      Scaler time data_max_: , {scaler_time.data_max_}\")\n",
    "                \n",
    "                log_message(f\"      Scaler polarization min_: , {scaler_y.min_}\")\n",
    "                log_message(f\"      Scaler polarization scale_: , {scaler_y.scale_}\")\n",
    "                log_message(f\"      Scaler polarization data_min_: , {scaler_y.data_min_}\")\n",
    "                log_message(f\"      Scaler polarization data_max_: , {scaler_y.data_max_}\")\n",
    "            \n",
    "            #9. Save the scalers. This is useful because otherwise we have no way to use the model outside of the loop (because we don't know how to unscale the values)\n",
    "            joblib.dump(scaler_static, win_long_path(str(output_subfolder / f\"scaler_static_{mode}.pkl\")))\n",
    "            joblib.dump(scaler_time,   win_long_path(str(output_subfolder / f\"scaler_time_{mode}.pkl\")))\n",
    "            joblib.dump(scaler_y,      win_long_path(str(output_subfolder / f\"scaler_y_{mode}.pkl\")))\n",
    "            log_message(f\"Saved scalers for mode {mode} to: {output_subfolder}\")\n",
    "\n",
    "            #10. Train the model on the augmented experiments. The experiments should enter unscaled and be scalerd inside)\n",
    "            model = train(\n",
    "                encoded_experiments=encoded_experiments,  \n",
    "                scaler_static=scaler_static,\n",
    "                scaler_time=scaler_time,\n",
    "                scaler_y=scaler_y,\n",
    "                model_type=model_type,\n",
    "                use_uncertainty=use_uncertainty,\n",
    "                mode=mode)\n",
    "\n",
    "\n",
    "            model_path = output_subfolder / f\"model_{mode}.keras\"\n",
    "            #model.save(win_long_path(str(model_path)))\n",
    "            log_message(f\"Saved model to {model_path}\")\n",
    "\n",
    "\n",
    "            \n",
    "            #12. Load isolated experiment. Predictions will be done on this experiment. Aligning is required\n",
    "            isolated_experiments, static_columns_isolated = load_all_experiments(isolated_dir, polarization_column=mode)\n",
    "            isolated_experiments_aligned = align_static_vectors(\n",
    "                isolated_experiments,\n",
    "                static_columns_training=static_columns,\n",
    "                static_columns_isolated=static_columns_isolated\n",
    "            ) #unscaled\n",
    "            if LogNoise:\n",
    "                log_message(f\"      Number of isolated experiments aligned (should be one): {len(isolated_experiments_aligned)}\")\n",
    "                log_message(f\"      Example static vector (pre-scale): {isolated_experiments_aligned[0][0]}\")\n",
    "                log_message(f\"      Example time vector (pre-scale): {isolated_experiments_aligned[0][1]}\")\n",
    "                log_message(f\"      Example polarization vector (pre-scale): {isolated_experiments_aligned[0][2]}\")\n",
    "\n",
    "\n",
    "\n",
    "            #13. Building manually the dataset for the isolated experiment\n",
    "            for static, time, pol, unc in isolated_experiments_aligned: #all unscaled\n",
    "                if len(time) < 2:\n",
    "                    log_message(f\"Skipping experiment {i} due to insufficient time points\")\n",
    "                    continue  # skip too-short experiments\n",
    "            \n",
    "                #13.1 Extract the initial and final points, add them as parameters and fit the entire static vector\n",
    "                initial_dt, initial_p = time[0], pol[0]\n",
    "                final_dt, final_p = time[-1], pol[-1]\n",
    "                static_vector = static + [initial_dt, initial_p, final_dt, final_p] #unscaled\n",
    "                if LogNoise:\n",
    "                    log_message(f\"  Experiment static vector length (pre-scale): {len(static_vector)}\")\n",
    "                    log_message(f\"  Experiment static vector (pre-scale): {static_vector}\")\n",
    "                static_scaled = scaler_static.transform(np.array(static_vector).reshape(1, -1)).flatten() #scaled\n",
    "                if LogNoise:\n",
    "                    log_message(f\"  Experiment static vector (scaled): {static_scaled}\")\n",
    "                \n",
    "                #13.2 Scale time and polarization arrays (only intermediate points)\n",
    "                time_intermediate = np.array(time[1:-1]).reshape(-1, 1) # unscaled\n",
    "                time_scaled = scaler_time.transform(time_intermediate).flatten() #scaled\n",
    "                if LogNoise:\n",
    "                    log_message(f\"  Experiment time (pre-scale): {time_intermediate.flatten()}\")\n",
    "                    log_message(f\"  Experiment time (scaled): {time_scaled}\")\n",
    "                pol_intermediate = np.array(pol[1:-1]).reshape(-1, 1) #unscaled\n",
    "                pol_scaled = scaler_y.transform(pol_intermediate).flatten() #scaled\n",
    "                if LogNoise:\n",
    "                    log_message(f\"  Experiment polarization (pre-scale): {pol_intermediate.flatten()}\")\n",
    "                    log_message(f\"  Experiment polarization (scaled): {pol_scaled}\")\n",
    "                unc_intermediate = np.array(unc[1:-1]).reshape(-1, 1) #unscaled\n",
    "                if LogNoise:\n",
    "                    log_message(f\"  Experiment uncertainty: {unc_intermediate.flatten()}\")\n",
    "\n",
    "                \n",
    "\n",
    "                #13.3 Combine all structures so that the shape is correct for prediction\n",
    "                scaled_isolated_experiments = []\n",
    "                scaled_isolated_experiments.append((\n",
    "                    static_scaled, time_scaled, pol_scaled, unc_intermediate.flatten()\n",
    "                )) #scaled\n",
    "                \n",
    "                \n",
    "                #14 Check for shapes and create the final NumPy arrays of the experiment\n",
    "                X_static, X_time, y_true, u = [], [], [], []\n",
    "                for i, (static_scaled, time_scaled, pol_scaled, unc_intermediate) in enumerate(scaled_isolated_experiments):\n",
    "                    if LogNoise:\n",
    "                        log_message(f\"   static_scaled.shape = {static_scaled.shape}\")\n",
    "                        log_message(f\"   time_scaled.shape = {time_scaled.shape}\")\n",
    "                        log_message(f\"   pol_scaled.shape = {pol_scaled.shape}\")\n",
    "                        log_message(f\"   unc_intermediate.shape = {unc_intermediate.shape}\")\n",
    "                    assert len(time_scaled) == len(pol_scaled) == len(unc_intermediate), \"Mismatch in lengths!\"\n",
    "\n",
    "                for static_scaled, time_scaled, pol_scaled, unc_intermediate in scaled_isolated_experiments:\n",
    "                    for t, p, err in zip(time_scaled, pol_scaled, unc_intermediate):\n",
    "                        X_static.append(static_scaled)   # already includes appended time/polarization info\n",
    "                        X_time.append([t])               # wrap to preserve 2D structure for Conv1D\n",
    "                        y_true.append(p)\n",
    "                        u.append(err)\n",
    "                X_static = np.array(X_static) #scaled\n",
    "                X_time = np.array(X_time) #scaled\n",
    "                y_true = np.array(y_true).reshape(-1, 1) #scaled\n",
    "                u = np.array(u).reshape(-1, 1) #unscaled\n",
    "\n",
    "                if LogNoise:\n",
    "                    log_message(f\"  X_static.shape: {X_static.shape}\")\n",
    "                    log_message(f\"  X_time.shape: {X_time.shape}\")\n",
    "                    log_message(f\"  y_true.shape: {y_true.shape}\")\n",
    "                    log_message(f\"  X_static[0]: {X_static[0]} (scaled)\")\n",
    "\n",
    "            #15 Extract the initial and final polarizations and keep a scaled and unscaled version of all. Then predict at those time points. \n",
    "            #Unscaling needs to be done with static_scaler but then we need to scale them as polarizations or as time points with their respective scalers so that we can use model_predict\n",
    "            X_static_raw = scaler_static.inverse_transform(X_static)\n",
    "            # Extract static input (already scaled)\n",
    "            x_static_single = X_static[0:1]  # shape (1, D_static)\n",
    "            t0_raw = X_static_raw[0, -4].reshape(1, -1)\n",
    "            p0_raw = X_static_raw[0, -3].reshape(1, -1)\n",
    "            tT_raw = X_static_raw[0, -2].reshape(1, -1)\n",
    "            pT_raw = X_static_raw[0, -1].reshape(1, -1)\n",
    "\n",
    "            t0_scaled_correct = scaler_time.transform(t0_raw)\n",
    "            tT_scaled_correct = scaler_time.transform(tT_raw)\n",
    "            p0_scaled_correct = scaler_y.transform(p0_raw)\n",
    "            pT_scaled_correct = scaler_y.transform(pT_raw)\n",
    "            \n",
    "            # Predict scaled polarizations at those time points\n",
    "            pred_initial_scaled = model_prediction(model, x_static_single, t0_scaled_correct)\n",
    "            pred_final_scaled   = model_prediction(model, x_static_single, tT_scaled_correct)\n",
    "            \n",
    "            # Inverse transform predictions to physical (real) polarizations\n",
    "            p0_pred = scaler_y.inverse_transform(pred_initial_scaled[:, 0:1])\n",
    "            pT_pred = scaler_y.inverse_transform(pred_final_scaled[:, 0:1])\n",
    "\n",
    "            if LogNoise:\n",
    "                log_message(f\"t0 (real) = {t0_raw}, tT (real) = {tT_raw}\")\n",
    "                log_message(f\"p0_pred (real) = {p0_pred}, pT_pred (real) = {pT_pred}\")\n",
    "                log_message(f\"p0 (true) = {p0_raw}, pT (true) = {pT_raw}\")\n",
    "\n",
    "\n",
    "            #16 Prepare the linear correction and predict in the time points where we have data\n",
    "            m_raw = ( (p0_pred-p0_raw) - (pT_pred-pT_raw) ) / (t0_raw-tT_raw)\n",
    "            n_raw = (p0_pred-p0_raw) - m_raw * t0_raw\n",
    "            if Correction == True:\n",
    "                y_pred_raw = model_predict_corrected(model, X_static, X_time, m_raw, n_raw, scaler_y, scaler_time) #Input es scaled, parametros unsacles, output es scaled también\n",
    "            else:\n",
    "                y_pred_raw = model_prediction(model, X_static, X_time)\n",
    "                \n",
    "            #To obtain the results we separate the value predictions form the log variance. The results need to be unscaled to real units while the uncertainty needs to be \n",
    "            #exponenciated (to obtain a variance), multiplied by the same factor that is used in MinMaxScaler and finally convert to uncertainty (take the square root)\n",
    "            mean_pred = scaler_y.inverse_transform(y_pred_raw[:, 0:1]).flatten()\n",
    "            log_var_scaled = y_pred_raw[:, 1]  # Keep in original scale\n",
    "            var_scaled = np.exp(log_var_scaled)\n",
    "            scale_y = scaler_y.data_max_[0] - scaler_y.data_min_[0]  # scale factor from MinMaxScaler \n",
    "            # Variance rescales by the square of the scale factor\n",
    "            var_rescaled = var_scaled * (scale_y ** 2)\n",
    "            pred_sigma = np.sqrt(var_rescaled)\n",
    "            pred_polar = mean_pred\n",
    "\n",
    "\n",
    "            #17. Plot the raw values (black), the predictions for those time points (blue) and predictions every 1000 seconds (red if there is no correction, green if there is correction)\n",
    "            if use_uncertainty:\n",
    "                suffix=\"Uncertainty\"\n",
    "            else:\n",
    "                suffix=\"noUncertainty\"\n",
    "            #Begin plotting:\n",
    "            color_true = \"black\"\n",
    "            color_pred = \"blue\"\n",
    "            color_grid = \"green\"\n",
    "            log_message(f\"Plot raw values, predictions for those time points and predictions every 1000 seconds.\")\n",
    "            # === Flatten inputs\n",
    "            true_polar_scaled = y_true.flatten() #scaled\n",
    "            real_uncertainty = u.flatten() #unscaled\n",
    "            delta_time_scaled = X_time.flatten()  #scaled\n",
    "            # Reshape to (-1, 1) for scaler inverse transform\n",
    "            true_polar_scaled_reshaped = true_polar_scaled.reshape(-1, 1)\n",
    "            delta_time_scaled_reshaped = delta_time_scaled.reshape(-1, 1)\n",
    "            \n",
    "            # Inverse transform to get unscaled values\n",
    "            true_polar_unscaled = scaler_y.inverse_transform(true_polar_scaled_reshaped).flatten()\n",
    "            delta_time_unscaled = scaler_time.inverse_transform(delta_time_scaled_reshaped).flatten()\n",
    "\n",
    "            # === Define grid for red line\n",
    "\n",
    "            grid_times = np.arange(0, max(delta_time_unscaled) + 1000, 1000).reshape(-1, 1)\n",
    "            \n",
    "            static_scaled = np.tile(X_static[0], (len(grid_times), 1)) #SCALED\n",
    "\n",
    "            time_scaled = scaler_time.transform(grid_times)\n",
    "\n",
    "            # === Predict on grid\n",
    "            if Correction == True:\n",
    "                pred_scaled_grid = model_predict_corrected(model, static_scaled, time_scaled, m_raw, n_raw, scaler_y, scaler_time) #scaled\n",
    "                # The old non-corrected prediction just for show\n",
    "                non_corrected_grid = model_prediction(model, static_scaled, time_scaled) #scaled\n",
    "                mu_non = scaler_y.inverse_transform(non_corrected_grid[:, 0:1]) #unscaled\n",
    "                log_non_var_grid_scaled = pred_scaled_grid[:, 1:2]  # Don't transform this #scaled\n",
    "                non_sigma = np.sqrt( np.exp(log_non_var_grid_scaled) * (scale_y ** 2) ) #unscaled\n",
    "            else:\n",
    "                pred_scaled_grid = model_prediction(model, static_scaled, time_scaled)\n",
    "            mu_pred_grid = scaler_y.inverse_transform(pred_scaled_grid[:, 0:1]) #unscaled\n",
    "            log_var_grid_scaled = pred_scaled_grid[:, 1:2]  # Don't transform this\n",
    "            var_grid_scaled = np.exp(log_var_grid_scaled)\n",
    "\n",
    "\n",
    "            # Variance rescales by the square of the scale factor\n",
    "            var_grid_rescaled = var_grid_scaled * (scale_y ** 2)\n",
    "            sigma_grid = np.sqrt(var_grid_rescaled) #unscaled\n",
    "\n",
    "           \n",
    "                # Convert scaled inputs back to real units for plotting\n",
    "\n",
    "            \n",
    "            # Convert scaled inputs back to real units for plotting\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            # base_name = \"PolarizationD3_CaFeAl_1_5_6_24_0_MillerIndex_(0,0,2)\"\n",
    "            \n",
    "            # Split by underscores\n",
    "            parts = base_name.split(\"_\")\n",
    "            \n",
    "            # Extract the fixed portion you want: \"CaFeAl_1_5_6_24_0\"\n",
    "            core_name = \"_\".join(parts[1:6])  \n",
    "            \n",
    "            # Build new title\n",
    "            title = f\"{core_name}_{Complexity}_{num_augmentations}\"\n",
    "            ax.set_title(title)\n",
    "            ax.grid(True)\n",
    "            \n",
    "            # Black dots with error bars (truth) - using real units\n",
    "            ax.scatter(delta_time_unscaled, true_polar_unscaled, color=color_true, marker='o', s=40, label=\"True\")\n",
    "            ax.errorbar(delta_time_unscaled, true_polar_unscaled, yerr=real_uncertainty, fmt='none',\n",
    "                        ecolor=color_true, alpha=0.6, capsize=3, label=\"Real ±σ\")\n",
    "            \n",
    "            # Green dots with model error - should already be in real units\n",
    "            ax.scatter(delta_time_unscaled, pred_polar, color=color_pred, marker='x', s=40, label=\"Prediction\")\n",
    "            \n",
    "            # Red line + band for prediction grid\n",
    "            ax.scatter(grid_times.flatten(), mu_pred_grid.flatten(), color=color_grid, alpha=0.7, label=\"Pred Points\", marker='x', s=40)\n",
    "            \n",
    "            if Correction == True:\n",
    "\n",
    "                ax.scatter(grid_times.flatten(), mu_non.flatten(), color='red', alpha=0.7, label=\"No Correction\", marker='x', s=40)\n",
    "                ax.fill_between(\n",
    "                    grid_times.flatten(),\n",
    "                    (mu_non - non_sigma).flatten(),\n",
    "                    (mu_non + non_sigma).flatten(),\n",
    "                    color='red',\n",
    "                    alpha=0.1,\n",
    "                    label=\"No correction ±1σ\")\n",
    "            ax.fill_between(\n",
    "                grid_times.flatten(),\n",
    "                (mu_pred_grid - sigma_grid).flatten(),\n",
    "                (mu_pred_grid + sigma_grid).flatten(),\n",
    "                color=color_grid,\n",
    "                alpha=0.2,\n",
    "                label=\"Predicted ±1σ\"\n",
    "            )\n",
    "\n",
    "            # Tight Y-limits\n",
    "            #y_min = min(np.min(true_polar), np.min(mu_pred_grid)) - 0.05\n",
    "            y_min = np.min(true_polar_unscaled - real_uncertainty) - 0.02\n",
    "            #y_max = max(np.max(true_polar), np.max(mu_pred_grid)) + 0.05\n",
    "            y_max = np.max(true_polar_unscaled + real_uncertainty) + 0.02\n",
    "            ax.set_ylim([y_min, y_max])\n",
    "            \n",
    "            ax.legend()\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            # === Save Figure\n",
    "            fig_filename = f\"Missing{base_name}\"\n",
    "            fig_path = output_subfolder / fig_filename\n",
    "            log_message(f\"Saved figure to: {fig_path}\")\n",
    "            fig.savefig(win_long_path(str(fig_path.with_suffix(\".jpg\"))), dpi=100)\n",
    "            plt.close(fig)\n",
    "            del fig, ax\n",
    "            gc.collect()\n",
    "            log_message(f\"Saved figure to: {fig_path.with_suffix('.jpg')}\")\n",
    "\n",
    "            \n",
    "            #18. Plot the difference between the predictions and the real values.\n",
    "            log_message(f\"Plot the difference between the predictions and the real values\")\n",
    "            delta_polar = pred_polar - true_polar_unscaled\n",
    "            delta_uncertainty = np.sqrt(pred_sigma**2 + real_uncertainty**2)\n",
    "            \"\"\"\n",
    "            # === Plot difference\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            title = f\"Difference_{base_name}\"\n",
    "            ax.set_title(title)\n",
    "            ax.grid(True)\n",
    "            \n",
    "            # Black points: difference with error bars\n",
    "            ax.scatter(delta_time_unscaled, delta_polar, color=\"blue\", marker=\"o\", s=40, label=\"Predicted - True\")\n",
    "            ax.errorbar(\n",
    "                delta_time_unscaled, delta_polar, yerr=delta_uncertainty,\n",
    "                fmt='none', ecolor=\"blue\", alpha=0.6, capsize=3, label=\"±σ\"\n",
    "            )\n",
    "            \n",
    "            # Zero line for reference\n",
    "            ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "            \n",
    "            ax.set_xlabel(\"DeltaTime\")\n",
    "            ax.set_ylabel(\"Predicted - True Polarization\")\n",
    "            ax.legend()\n",
    "            fig.tight_layout()\n",
    "            diff_plot_path = output_subfolder / f\"Difference_{base_name}.png\"\n",
    "            fig.savefig(win_long_path(str(diff_plot_path)), dpi=300, bbox_inches=\"tight\")\n",
    "            log_message(f\"Saved difference plot to: {diff_plot_path}\")\n",
    "            plt.close(fig)  # free memory\n",
    "            \"\"\"\n",
    "            #19. Save all predictions and raw data in text files === Save data to text file\n",
    "            diff_data_path = output_subfolder / f\"Difference_{base_name}.txt\"\n",
    "            with open(win_long_path(str(diff_data_path)), 'w') as f:\n",
    "                f.write(\"DeltaTime\\tDeltaPolarization\\tDeltaUncertainty\\n\")\n",
    "                for t, dp, du in zip(delta_time_unscaled, delta_polar, delta_uncertainty):\n",
    "                    f.write(f\"{t:.6f}\\t{dp:.6f}\\t{du:.6f}\\n\")\n",
    "            log_message(f\"Saved difference data to: {diff_data_path}\")\n",
    "\n",
    "            # Save true points\n",
    "            raw_data_path = output_subfolder / f\"RawData_{mode}_Missing{base_name}.txt\"\n",
    "            with open(win_long_path(str(raw_data_path)), 'w') as f:\n",
    "                f.write(\"DeltaTime\\tRealPolarizationD3\\tErrRealPolarizationD3\\n\")\n",
    "                for t, p, e in zip(delta_time_unscaled, true_polar_unscaled, real_uncertainty):\n",
    "                    f.write(f\"{t:.6f}\\t{p:.6f}\\t{e:.6f}\\n\")\n",
    "            log_message(f\"Saved raw data to: {raw_data_path}\")\n",
    "\n",
    "            # Save red line predictions\n",
    "            predicted_data_path = output_subfolder / f\"PredictedData_{mode}_Missing{base_name}.txt\"\n",
    "            with open(win_long_path(str(predicted_data_path)), 'w') as f:\n",
    "                f.write(\"GridTime\\tPredictedPolarizationD3\\tErrPredictedPolarizationD3\\n\")\n",
    "                for t, p, s in zip(grid_times.flatten(), mu_pred_grid.flatten(), sigma_grid.flatten()):\n",
    "                    f.write(f\"{t:.6f}\\t{p:.6f}\\t{s:.6f}\\n\")\n",
    "            log_message(f\"Saved predicted data to: {predicted_data_path}\")\n",
    "\n",
    "            # Save predicted values at original timepoints (green points)\n",
    "            predicted_points_path = output_subfolder / f\"PredictedPoints_{mode}_Missing{base_name}.txt\"\n",
    "            with open(win_long_path(str(predicted_points_path)), 'w') as f:\n",
    "                f.write(\"DeltaTime\\tPredictedPolarizationD3\\tErrPredictedPolarizationD3\\n\")\n",
    "                for t, p, s in zip(delta_time_unscaled, pred_polar, u.flatten()):\n",
    "                    f.write(f\"{t:.6f}\\t{p:.6f}\\t{s:.6f}\\n\")\n",
    "            log_message(f\"Saved predicted point data to: {predicted_points_path}\")\n",
    "\n",
    "        #21. Move all experiments back to the original folder \n",
    "        shutil.move(win_long_path(str(isolated_dir / file_param.name)), win_long_path(str(file_param)))\n",
    "        shutil.move(win_long_path(str(isolated_dir / file_data.name)), win_long_path(str(file_data)))\n",
    "        log_message(f\"Returned {base_name} to MLDataBase\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "12. MAIN CODE\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "First we make sure all folders are created and then we run the isolate_experiments function that will loop over all experiments\n",
    "\"\"\"\n",
    "# Define your paths\n",
    "isolated_dir = Path(\"../FileReadingStoring/CrystallineMLIsolatedExperiment\").resolve()\n",
    "data_dir = Path(\"../FileReadingStoring/CrystallineMLDataBase/\").resolve()\n",
    "\n",
    "os.makedirs(win_long_path(isolated_dir), exist_ok=True)\n",
    "os.makedirs(win_long_path(data_dir), exist_ok=True) \n",
    "Correction = True\n",
    "\n",
    "# Move all files back\n",
    "for file_path in isolated_dir.iterdir():  # iterates Path objects\n",
    "    if file_path.is_file():  # only move files\n",
    "        dst = data_dir / file_path.name\n",
    "        shutil.move(win_long_path(file_path), win_long_path(dst))\n",
    "        log_message(f\"Moved {file_path.name} back to {data_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for Complexity in [\"SimpleNoDropout1648\", \"NaifTwiceDense24216\", \"NaifTwiceDense824\", \"NaifTwiceDense24124\", \"SimpleNoDropout4164\"]:\n",
    "    print(Complexity)\n",
    "    build_model = Define_Complexity(Complexity)\n",
    "    for num_augmentations in [2,3,4,5,5,6,7,8,9,10,11,12,13,14,15,16]:  # Augmentations\n",
    "        log_message(f\"Begin {Complexity} model with {num_augmentations} augmentations\")\n",
    "        print(num_augmentations)\n",
    "\n",
    "        # Move all files back\n",
    "        for file_path in isolated_dir.iterdir():  # iterates Path objects\n",
    "            if file_path.is_file():  # only move files\n",
    "                dst = data_dir / file_path.name\n",
    "                shutil.move(win_long_path(file_path), win_long_path(dst))\n",
    "                log_message(f\"Moved {file_path.name} back to {data_dir}\")\n",
    "\n",
    "        # Path to the log file\n",
    "        log_file = Path(\"CrystallineExecution_time.txt\")\n",
    "        os.makedirs(win_long_path(log_file.parent), exist_ok=True)\n",
    "\n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "        folder_to_delete = Path(f\"CrystallineAllTestsFolder_{Complexity}_{num_augmentations}\").resolve()\n",
    "        if folder_to_delete.exists() and folder_to_delete.is_dir():\n",
    "            shutil.rmtree(win_long_path(folder_to_delete))\n",
    "            log_message(f\"Deleted folder: {folder_to_delete}\")\n",
    "        else:\n",
    "            log_message(f\"Folder does not exist: {folder_to_delete}\")\n",
    "\n",
    "        # Recreate output folder\n",
    "        output_folder = Path(f\"CrystallineAllTestsFolder_{Complexity}_{num_augmentations}\").resolve()\n",
    "        os.makedirs(win_long_path(output_folder), exist_ok=True)\n",
    "\n",
    "        # Run main function\n",
    "        use_uncertainty = True\n",
    "        Correction = True\n",
    "        isolate_experiments(\n",
    "            data_dir=win_long_path(data_dir),\n",
    "            isolated_dir=win_long_path(isolated_dir),\n",
    "            model_type=model_type,\n",
    "            output_folder=win_long_path(output_folder),\n",
    "            use_uncertainty=use_uncertainty,\n",
    "            num_augmentations=num_augmentations,\n",
    "            Correction=Correction,\n",
    "            build_model=build_model\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Write to log file safely with long path\n",
    "        with open(win_long_path(str(log_file)), \"a\") as f:\n",
    "            f.write(f\"Execution time={elapsed_time:.6f} seconds for Crystal {Complexity} {num_augmentations}\\n\")\n",
    "\n",
    "        log_message(\n",
    "            f\"Execution finished in {elapsed_time:.6f} seconds \"\n",
    "            f\"(Complexity={Complexity}, Augmentations={num_augmentations}). \"\n",
    "            f\"Logged to {log_file}\"\n",
    "        )\n",
    "        log_message(f\"\\n _______________________________________________________ \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
