{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4883b95c-2915-473b-a8ab-4c7c474ba96b",
   "metadata": {},
   "source": [
    "<h1> LTestChiSquaredTests.ipynb </h1>\n",
    "\n",
    "This code is prepared so that it condenses all the information from the code files inside TestAModelFolder/ML. \n",
    "\n",
    "First copy and paste the folders that CrystallineMLAlone.ipynb and AmorphousMLAlone.ipynb have created inside LTestVisualCheck/Models_to_be_predicted.\n",
    "Then run all the cells (skip the last one if you don't want images that take a lot of time and space) if you want to obtain information using the chi squared metric. These cells will create a subfolder called Results where only three files are important:\n",
    "1. **Chi2\\_rank\\_vertical.png** For every experiment, the chi squared value of the preditions of each model is obtained. Then all chi squared values of the different models in each experiment is compared. The one that has the smaller chi squared value obtains a +1, the second smallest a +2 and so on. This process is repeated for each experiment and these integer values are summed. At the end we can say that the model with the smallest score has performed better overall\n",
    "2. **Chi2\\_AccumulativeScores.txt** has the same information than the graph but on a txt file\n",
    "3. **Chi2\\_NumberOfExperimentsWhereEachModelOutperforms.txt** as its name indicates counts only the number of experiment where each model obtains the smallest chi squared value. Sometimes, models that overfit perform better on this test (as they pass through all the points)\n",
    "\n",
    "\n",
    "If you run the last one it will automatically combine the predictions for each experiment in a single image. This way it is easier to spot the differences between models in a quick look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e008a2a8-b8df-4b2a-8d3d-61a2fc3f7e25",
   "metadata": {},
   "source": [
    "<H1> CHI SQUARED TEST </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957eaa3-a94f-4c5f-8ad6-000aa7b19d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import re\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def long_path(path):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        path (path): The path that needs to be converted\n",
    "\n",
    "    Returns:\n",
    "        The updated path string or path depending on the platform used\n",
    "\n",
    "    Notes:\n",
    "        To avoid Windows 260 character limit for Windows paths, a special \"prefix\" is added.\n",
    "        It also unifies how directories are managed.\n",
    "        Also works with Linux and Mac\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert to Path and resolve to absolute\n",
    "    path = Path(path).resolve()\n",
    "\n",
    "    #Windows only:\n",
    "    if os.name == \"nt\":\n",
    "        path_str = str(path)\n",
    "        if not path_str.startswith(\"\\\\\\\\?\\\\\"):\n",
    "            if path_str.startswith(\"\\\\\\\\\"):\n",
    "                path_str = \"\\\\\\\\?\\\\UNC\\\\\" + path_str[2:]\n",
    "            else:\n",
    "                path_str = \"\\\\\\\\?\\\\\" + path_str\n",
    "            return path_str\n",
    "\n",
    "    return path\n",
    "def compute_chi2_for_experiment(df_real, df_pred):\n",
    "    \"\"\"\n",
    "    Compute the reduced chi-squared value as the sum of tipyfied normal distributions over the number of distributions\n",
    "    \n",
    "        χ^2 = (1/N) * \\sum [ (pred - real)^2 / (err_real)^2 ]\n",
    "    \"\"\"\n",
    "    if len(df_real) != len(df_pred):\n",
    "        raise ValueError(\"Real and predicted files must have the same length.\")\n",
    "    \n",
    "    N = len(df_real)\n",
    "    diff = df_pred[\"PredictedPolarizationD3\"].values - df_real[\"RealPolarizationD3\"].values\n",
    "    err = df_real[\"ErrRealPolarizationD3\"].values\n",
    "    err[err == 0] = 1e-10  # avoid division by zero\n",
    "    \n",
    "    chi2 = np.sum((diff**2) / (err**2)) / N\n",
    "    return chi2\n",
    "\n",
    "\n",
    "def load_data(experiment_folder):\n",
    "    \"\"\"\n",
    "    Load the txt files containing real and predicted data\n",
    "    for a MissingPolarizationD3_* experiment.\n",
    "    \"\"\"\n",
    "    experiment_folder = long_path(experiment_folder)\n",
    "    files = [long_path(os.path.join(experiment_folder, f)) for f in os.listdir(experiment_folder)]\n",
    "\n",
    "    real_file = next(f for f in files if os.path.basename(f).startswith(\"RawData_PolarizationD3_MissingPolarizationD3_\"))\n",
    "    pred_file = next(f for f in files if os.path.basename(f).startswith(\"PredictedPoints_PolarizationD3_MissingPolarizationD3_\"))\n",
    "\n",
    "    df_real = pd.read_csv(real_file, sep=\"\\t\")\n",
    "    df_pred = pd.read_csv(pred_file, sep=\"\\t\")\n",
    "    return df_real, df_pred\n",
    "\n",
    "\n",
    "def count_missing_folders(model_path):\n",
    "    \"\"\"\n",
    "    Return the list of MissingPolarizationD3_* subfolders for a given model folder.\n",
    "    \"\"\"\n",
    "    model_path = long_path(model_path)\n",
    "    return sorted([\n",
    "        f for f in os.listdir(model_path)\n",
    "        if f.startswith(\"MissingPolarizationD3_\") and os.path.isdir(long_path(os.path.join(model_path, f)))\n",
    "    ])\n",
    "\n",
    "\n",
    "def save_chi2_values_to_txt(model_folder_name, missing_folders, chi2_values, output_dir):\n",
    "    \"\"\"\n",
    "    Save the chi-squared values to a structured text file\n",
    "    inside the 'Results' folder at the root level.\n",
    "    \"\"\"\n",
    "    chi2_dir = long_path(os.path.join(output_dir, \"Results\"))\n",
    "    os.makedirs(chi2_dir, exist_ok=True)  # ensure folder exists\n",
    "\n",
    "    filename = f\"Chi2_values_{model_folder_name}.txt\"\n",
    "    filepath = long_path(os.path.join(chi2_dir, filename))\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for folder_name, chi2 in zip(missing_folders, chi2_values):\n",
    "            f.write(f\"{folder_name}: {chi2:.6f}\\n\")\n",
    "\n",
    "    print(f\"File saved: {filepath}\")\n",
    "\n",
    "\n",
    "def main_all_models(root_folder):\n",
    "    root_folder = long_path(root_folder)\n",
    "\n",
    "    models_root = long_path(os.path.join(root_folder, \"Models_to_be_compared\"))\n",
    "\n",
    "    if not os.path.isdir(models_root):\n",
    "        print(f\"Models folder not found: {models_root}\")\n",
    "        return\n",
    "\n",
    "    all_model_folders = [\n",
    "        d for d in os.listdir(models_root)\n",
    "        if os.path.isdir(long_path(os.path.join(models_root, d)))\n",
    "    ]\n",
    "\n",
    "    if not all_model_folders:\n",
    "        print(\"No model folders found.\")\n",
    "        return\n",
    "\n",
    "    for model_folder in all_model_folders:\n",
    "        model_path = long_path(os.path.join(models_root, model_folder))\n",
    "        missing_folders = count_missing_folders(model_path)\n",
    "\n",
    "        if not missing_folders:\n",
    "            print(f\" No MissingPolarizationD3_ folders in {model_folder}\")\n",
    "            continue\n",
    "\n",
    "        chi2_values = []\n",
    "        for missing_folder in missing_folders:\n",
    "            experiment_path = long_path(os.path.join(model_path, missing_folder))\n",
    "            try:\n",
    "                df_real, df_pred = load_data(experiment_path)\n",
    "                chi2 = compute_chi2_for_experiment(df_real, df_pred)\n",
    "                chi2_values.append(chi2)\n",
    "            except Exception as e:\n",
    "                print(f\"   Error in {missing_folder}: {e}\")\n",
    "\n",
    "        if chi2_values:\n",
    "            save_chi2_values_to_txt(model_folder, missing_folders, chi2_values, root_folder)\n",
    "            chi2_mean = np.mean(chi2_values)\n",
    "        else:\n",
    "            print(f\"No valid chisquared values computed for {model_folder}.\")\n",
    "\n",
    "main_all_models(r\".\")\n",
    "folder_path = long_path(\"Results\")\n",
    "if not os.path.isdir(folder_path):\n",
    "    print(f\"Folder not found: {folder_path}\")\n",
    "    print(\"   Tip: run the computation cell first so it creates Results/ and the files.\")\n",
    "def is_result_file(name: str) -> bool:\n",
    "    return (\n",
    "        name.endswith(\".txt\") and\n",
    "        (name.startswith(\"Chi2_values_\") or name.startswith(\"ChiSquared_values_\"))\n",
    "    )\n",
    "\n",
    "# Initialize dictionaries\n",
    "Chi2Values = {}             \n",
    "ExperimentName = OrderedDict() \n",
    "\n",
    "# Collect files\n",
    "result_files = []\n",
    "if os.path.isdir(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        filename = long_path(os.path.join(folder_path, filename))  # wrap early\n",
    "        if is_result_file(os.path.basename(filename)):\n",
    "            result_files.append(filename)\n",
    "\n",
    "result_files.sort()\n",
    "if not result_files:\n",
    "    print(\"No results found in ChiSquared/ matching 'Chi2_values_*.txt' or 'ChiSquared_values_*.txt'.\")\n",
    "else:\n",
    "    for full_path in result_files:\n",
    "        with open(full_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        Chi2Values[os.path.basename(full_path)] = {}\n",
    "        for line in lines:\n",
    "            if \":\" in line:\n",
    "                try:\n",
    "                    experiment_name, value = line.split(\":\", 1)\n",
    "                    experiment_name = experiment_name.strip()\n",
    "                    value = float(value.strip())\n",
    "                    Chi2Values[os.path.basename(full_path)][experiment_name] = value\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping malformed line in {full_path}: {line.strip()}\")\n",
    "\n",
    "        if not ExperimentName and Chi2Values[os.path.basename(full_path)]:\n",
    "            for i, experiment_name in enumerate(Chi2Values[os.path.basename(full_path)].keys(), 1):\n",
    "                ExperimentName[experiment_name] = f\"exp{i}\"\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "exp_ids = list(ExperimentName.values())\n",
    "assert len(Chi2Values) >= 2, \"You need at least two chisquared values files\"\n",
    "files = list(Chi2Values.keys())\n",
    "\n",
    "try:\n",
    "    cmap = plt.colormaps.get_cmap('tab20')  # new API\n",
    "except AttributeError:\n",
    "    cmap = plt.get_cmap('tab20')  # old API\n",
    "\n",
    "colors = cmap.colors\n",
    "line_styles = ['-', '--', ':', '-.', (0, (5, 1)), (0, (3, 1, 1, 1))]\n",
    "line_widths = [2] * len(files)\n",
    "\n",
    "for j, filename in enumerate(files):\n",
    "    chi2_values = [\n",
    "        Chi2Values[filename].get(exp_name, np.nan)  # Use NaN if missing\n",
    "        for exp_name in ExperimentName.keys()\n",
    "    ]\n",
    "    \n",
    "    plt.plot(\n",
    "        range(len(exp_ids)),\n",
    "        chi2_values,\n",
    "        color=colors[j % len(colors)],\n",
    "        linestyle=line_styles[j % len(line_styles)],\n",
    "        linewidth=line_widths[j],\n",
    "        label=filename\n",
    "    )\n",
    "\n",
    "xticks_pos = [i for i in range(len(exp_ids)) if (i + 1) % 10 == 0]\n",
    "xticks_labels = [exp_ids[i] for i in xticks_pos]\n",
    "plt.xticks(xticks_pos, xticks_labels, rotation=45, ha='right')\n",
    "\n",
    "plt.xlabel(\"Experiment\", fontsize=12)\n",
    "plt.ylabel(r\"$\\chi^2$\", fontsize=12)\n",
    "plt.title(r\"Chi-squared values per experiment (model comparison)\", fontsize=14)\n",
    "plt.grid(alpha=0.2, linestyle='--')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def normalize_key(k):\n",
    "    return k.replace(\"-\", \"_\")\n",
    "\n",
    "Chi2Values_norm = {\n",
    "    model: {normalize_key(exp): val for exp, val in Chi2Values[model].items()}\n",
    "    for model in Chi2Values\n",
    "}\n",
    "ExperimentName_norm = {normalize_key(exp): exp for exp in ExperimentName.keys()}\n",
    "all_chi2_values = np.array([\n",
    "    [Chi2Values_norm[f].get(exp, np.nan) for exp in ExperimentName_norm.keys()]\n",
    "    for f in Chi2Values_norm.keys()\n",
    "])\n",
    "\n",
    "\n",
    "exp_ids = [ExperimentName_norm[exp] for exp in ExperimentName_norm.keys()]\n",
    "model_ids = list(Chi2Values_norm.keys())  \n",
    "files = list(Chi2Values.keys())  \n",
    "nb_models = len(files)\n",
    "exp_ids = list(ExperimentName.keys())  \n",
    "\n",
    "all_chi2_values = []\n",
    "for f in files:\n",
    "    model_vals = []\n",
    "    for exp in exp_ids:\n",
    "        if exp not in Chi2Values[f]:\n",
    "            print(f\"Warning: experiment '{exp}' missing for model '{f}'\")\n",
    "            model_vals.append(np.nan) \n",
    "        else:\n",
    "            model_vals.append(Chi2Values[f][exp])\n",
    "    all_chi2_values.append(model_vals)\n",
    "all_chi2_values = np.array(all_chi2_values)\n",
    "\n",
    "\n",
    "avg_chi2 = np.nanmean(all_chi2_values, axis=0)  \n",
    "try:\n",
    "    cmap = plt.colormaps['tab20']   \n",
    "except (AttributeError, TypeError):\n",
    "    cmap = plt.get_cmap('tab20')  \n",
    "\n",
    "colors = cmap(range(nb_models))\n",
    "\n",
    "# Plot deviation from the average\n",
    "plt.figure(figsize=(18, 12))\n",
    "for j in range(nb_models):\n",
    "    diff_from_avg = all_chi2_values[j] - avg_chi2\n",
    "    plt.plot(\n",
    "        range(1, len(exp_ids) + 1), \n",
    "        diff_from_avg,\n",
    "        linewidth=2,\n",
    "        color=colors[j % len(colors)],\n",
    "        label=files[j]\n",
    "    )\n",
    "\n",
    "xticks_pos = [k + 1 for k in range(len(exp_ids)) if (k + 1) % 10 == 0]\n",
    "plt.xticks(xticks_pos, rotation=0)\n",
    "plt.xlabel(\"Experiment Index\", fontsize=12)\n",
    "plt.ylabel(\"ΔChisuared (model - average)\", fontsize=12)\n",
    "plt.title(\"Deviation of Chi squared values from experiment-wise average\", fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save number of wins (lowest Chi squared per experiment) \n",
    "output_folder = long_path(\"Results\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "model_scores = {f: 0 for f in files}\n",
    "for chi2_vals in all_chi2_values.T:\n",
    "    if np.all(np.isnan(chi2_vals)):\n",
    "        continue\n",
    "    min_index = np.nanargmin(chi2_vals)\n",
    "    winning_model = files[min_index]\n",
    "    model_scores[winning_model] += 1\n",
    "\n",
    "sorted_scores = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "output_file = long_path(os.path.join(output_folder, \"Chi2_NumberOfExperimentsWhereEachModelOutperforms.txt\"))\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"Approval Rate (Number of wins by minimal chisquared. The higher the better):\\n\\n\")\n",
    "    for model, score in sorted_scores:\n",
    "        f.write(f\"{model}: {score} points\\n\")\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Save rank-based accumulative scores\n",
    "all_chi2_values = []\n",
    "for f in files:\n",
    "    model_chi2 = []\n",
    "    for exp in exp_ids:\n",
    "        model_chi2.append(Chi2Values[f].get(exp, np.nan))\n",
    "    all_chi2_values.append(model_chi2)\n",
    "all_chi2_values = np.array(all_chi2_values)\n",
    "\n",
    "model_scores = {f: 0 for f in files}\n",
    "for chi_values in all_chi2_values.T:\n",
    "    sorted_indices = np.argsort(chi_values)  # best to worst\n",
    "    for rank, model_idx in enumerate(sorted_indices, start=1):\n",
    "        model_name = files[model_idx]\n",
    "        model_scores[model_name] += rank\n",
    "\n",
    "sorted_scores = sorted(model_scores.items(), key=lambda x: x[1])\n",
    "\n",
    "output_file = long_path(os.path.join(output_folder, \"Chi2_AccumulativeScores.txt\"))\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"Approval Rate (Score by rank. Lower is better):\\n\\n\")\n",
    "    for model, score in sorted_scores:\n",
    "        f.write(f\"{model}: {score} points\\n\")\n",
    "print(f\"Scores saved to {output_file}\")\n",
    "\n",
    "output_folder = long_path(\"Results\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "model_scores = {f: 0.0 for f in files}\n",
    "for chi2_vals in all_chi2_values.T:\n",
    "    if np.all(np.isnan(chi2_vals)):\n",
    "        continue\n",
    "    min_chi2 = np.nanmin(chi2_vals)\n",
    "    for idx, val in enumerate(chi2_vals):\n",
    "        if np.isnan(val):\n",
    "            score = 0.0\n",
    "        else:\n",
    "            score = min_chi2 / val \n",
    "        model_name = files[idx]\n",
    "        model_scores[model_name] += score\n",
    "\n",
    "# Normalize by number of experiments\n",
    "for model in model_scores:\n",
    "    model_scores[model] /= len(exp_ids)\n",
    "\n",
    "# Sort models (higher = better)\n",
    "sorted_scores = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# --- Save results ---\n",
    "output_file = long_path(os.path.join(output_folder, \"Chi2_RelativeNormalizedScores.txt\"))\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"Relative Score (Normalized chisqaured per experiment. Higher is better):\\n\\n\")\n",
    "    for model, score in sorted_scores:\n",
    "        f.write(f\"{model}: {score:.4f}\\n\")\n",
    "print(f\"Normalized relative scores saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Vertical bar chart: Rank-based scoring (lower = better)\n",
    "sorted_scores_rank = sorted(model_scores.items(), key=lambda x: x[1])\n",
    "models = [m for m, _ in sorted_scores_rank]\n",
    "scores = [s for _, s in sorted_scores_rank]\n",
    "\n",
    "norm = plt.Normalize(min(scores), max(scores))\n",
    "try:\n",
    "    cmap = plt.colormaps['RdYlGn_r']\n",
    "except (AttributeError, TypeError):\n",
    "    cmap = plt.get_cmap('RdYlGn_r')\n",
    "\n",
    "colors = cmap(norm(scores))\n",
    "short_models = [m.replace(\"Chi2_values_AllTestsFolder_\", \"\").replace(\".txt\", \"\") for m in models]\n",
    "short_models = [\"_\".join(m.split(\"_\")[-2:]) for m in short_models]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.bar(short_models, scores, color=colors)\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width()/2,\n",
    "        score + score * 0.02,\n",
    "        f\"{score:.3f}\".replace(',', '.'),\n",
    "        ha='center', va='bottom',\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(scores)\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Rank Score (Lower = Better)\")\n",
    "\n",
    "ax.set_ylabel(\"Total Rank Score\", fontsize=12)\n",
    "ax.set_xlabel(\"Model\", fontsize=12)\n",
    "ax.set_title(\"Approval Rate: Rank-Based Scoring (Chi², Green=Better, Red=Worse)\", fontsize=14)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(long_path(os.path.join(output_folder, \"Chi2_rank_vertical.png\")), dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Vertical bar chart: Relative normalized scoring (higher = better)\n",
    "sorted_scores_rel = sorted(model_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "models = [m for m, _ in sorted_scores_rel]\n",
    "scores = [s for _, s in sorted_scores_rel]\n",
    "\n",
    "short_models = [m.replace(\"Chi2_values_AllTestsFolder_\", \"\").replace(\".txt\", \"\") for m in models]\n",
    "short_models = [\"_\".join(m.split(\"_\")[-2:]) for m in short_models]\n",
    "\n",
    "norm = plt.Normalize(min(scores), max(scores))\n",
    "try:\n",
    "    cmap = plt.colormaps['RdYlGn']\n",
    "except (AttributeError, TypeError):\n",
    "    cmap = plt.get_cmap('RdYlGn')\n",
    "\n",
    "colors = cmap(norm(scores))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "bars = ax.bar(short_models, scores, color=colors, edgecolor='black')\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        score + score * 0.02,\n",
    "        f\"{score:.3f}\".replace(',', '.'),\n",
    "        ha='center', va='bottom',\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(scores)\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Relative Score (Higher = Better)\")\n",
    "\n",
    "ax.set_ylabel(\"Total Relative Score (averaged over experiments)\", fontsize=12)\n",
    "ax.set_xlabel(\"Model\", fontsize=12)\n",
    "ax.set_title(\"Approval Rate: Normalized Relative Scoring (chisquared, Green = Best, Red = Worst)\", fontsize=14)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "ax.set_ylim(0, max(scores) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(long_path(os.path.join(output_folder, \"Chi2_relative_vertical.png\")), dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23293ae4-8bea-4699-af93-83eb1128a480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pair models with scores\n",
    "model_scores = list(zip(short_models, scores))\n",
    "\n",
    "# Sort by score (ascending)\n",
    "model_scores_sorted = sorted(model_scores, key=lambda x: x[1])\n",
    "print(\"Models sorted by score (lowest -> highest):\")\n",
    "i=0\n",
    "for model, score in model_scores_sorted:\n",
    "    i=i+1\n",
    "    print(f\"{model}: {score:.3f}\")\n",
    "print(i)\n",
    "sorted_models, sorted_scores = zip(*model_scores_sorted)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "model_scores = list(zip(short_models, scores))\n",
    "\n",
    "# Sort by score (ascending -> worst at top, best at bottom)\n",
    "model_scores_sorted = sorted(model_scores, key=lambda x: x[1])\n",
    "\n",
    "# Unzip\n",
    "sorted_models, sorted_scores = zip(*model_scores_sorted)\n",
    "\n",
    "# Define colormap (red → yellow → green)\n",
    "cmap = cm.get_cmap(\"RdYlGn\")\n",
    "norm = mcolors.Normalize(vmin=min(sorted_scores), vmax=max(sorted_scores))\n",
    "colors = [cmap(norm(s)) for s in sorted_scores]\n",
    "fig, ax = plt.subplots(figsize=(10, len(sorted_models) * 0.15))\n",
    "bars = ax.barh(sorted_models, sorted_scores, color=colors, edgecolor=\"black\")\n",
    "\n",
    "ax.set_xlabel(\"Total Relative Score\", fontsize=12)\n",
    "ax.set_ylabel(\"Model\", fontsize=12)\n",
    "ax.set_title(\"Approval Rate: Sorted Scores (Red = Worst, Green = Best)\", fontsize=14)\n",
    "ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=9)\n",
    "ax.tick_params(axis=\"y\", labelsize=7)\n",
    "\n",
    "for bar, score in zip(bars, sorted_scores):\n",
    "    ax.text(\n",
    "        bar.get_width() + max(sorted_scores) * 0.01,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{score:.3f}\".replace(',', '.'),\n",
    "        va=\"center\", ha=\"left\", fontsize=8\n",
    "    )\n",
    "\n",
    "# Remove top/bottom empty space\n",
    "ax.set_ylim(-0.5, len(sorted_models) - 0)\n",
    "\n",
    "# Extend X-axis so labels fit\n",
    "ax.set_xlim(0, max(sorted_scores) * 1.1)\n",
    "\"\"\"\n",
    "# Add colorbar legend\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Relative Score (Higher = Better)\")\n",
    "\"\"\"\n",
    "plt.tight_layout()\n",
    "results_folder = long_path(\"Results\")\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "plt.savefig(\n",
    "    long_path(os.path.join(results_folder, \"FullVerticalChiCrystalline.png\")),\n",
    "    dpi=900,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b42e25-3a48-4e50-b529-60f45d038d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(model_name):\n",
    "    match = re.search(r'_(\\d+)$', model_name)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "model_scores = list(zip(short_models, scores))\n",
    "\n",
    "# Sort by numeric suffix (ascending: 1 -> N)\n",
    "model_scores_sorted = sorted(model_scores, key=lambda x: extract_number(x[0]))\n",
    "\n",
    "sorted_models, sorted_scores = zip(*model_scores_sorted)\n",
    "\n",
    "cmap = cm.get_cmap(\"RdYlGn\")\n",
    "norm = mcolors.Normalize(vmin=min(sorted_scores), vmax=max(sorted_scores))\n",
    "colors = [cmap(norm(s)) for s in sorted_scores]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, len(sorted_models) * 0.5))\n",
    "bars = ax.barh(sorted_models, sorted_scores, color=colors, edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Total Relative Score\", fontsize=12)\n",
    "ax.set_ylabel(\"Model\", fontsize=12)\n",
    "ax.set_title(\"Approval Rate: Ordered by Model Number (Red = Worst, Green = Best)\", fontsize=14)\n",
    "ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "ax.tick_params(axis=\"x\", labelsize=9)\n",
    "ax.tick_params(axis=\"y\", labelsize=7)\n",
    "\n",
    "for bar, score in zip(bars, sorted_scores):\n",
    "    ax.text(\n",
    "        bar.get_width() + max(sorted_scores) * 0.01,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{score:.3f}\".replace(',', '.'),\n",
    "        va=\"center\", ha=\"left\", fontsize=8\n",
    "    )\n",
    "\n",
    "ax.set_ylim(-0.5, len(sorted_models) - 0.5)\n",
    "ax.set_xlim(0, max(sorted_scores) * 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "results_folder = long_path(\"Results\")\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "plt.savefig(\n",
    "    long_path(os.path.join(results_folder, \"FullHorizontalChiCrystalline.png\")),\n",
    "    dpi=900,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc81ed-4c33-4b7e-bd27-5d2463382fb9",
   "metadata": {},
   "source": [
    "<h1> PLOTS COMPARING THE MODELS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a7af6-c0e5-4c2d-ae83-dc15ef06a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path.cwd()\n",
    "models_root = root_dir / \"Models_to_be_compared\"\n",
    "output_dir = root_dir / \"Results\" / \"ExperimentComparison\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helpers\n",
    "def best_subplot_shape(n):\n",
    "    \"\"\"Balanced grid for n images.\"\"\"\n",
    "    cols = math.ceil(math.sqrt(n))\n",
    "    rows = math.ceil(n / cols)\n",
    "    return rows, cols\n",
    "\n",
    "def extract_model_name(folder_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract model name from something like:\n",
    "    CrystallineAllTestsFolder_Naif81016_3\n",
    "    \"\"\"\n",
    "    match = re.search(r\"Naif[^_]+\", folder_name)\n",
    "    return match.group(0) if match else folder_name\n",
    "\n",
    "def shorten_experiment_name(exp_folder: str) -> str:\n",
    "    \"\"\"\n",
    "    Shorten experiment folder names for filenames.\n",
    "    \"\"\"\n",
    "    return exp_folder.replace(\"Missing\", \"\").strip(\"_\")\n",
    "\n",
    "# Find all Missing*.jpg images\n",
    "all_images = list(models_root.rglob(\"Missing*.jpg\"))\n",
    "print(f\"Found {len(all_images)} images total.\")\n",
    "\n",
    "# Group images by experiment\n",
    "experiments = {}\n",
    "\n",
    "for img_path in all_images:\n",
    "    exp_name = img_path.parent.name         \n",
    "    model_folder = img_path.parents[1].name \n",
    "\n",
    "    model_name = extract_model_name(model_folder)\n",
    "\n",
    "    experiments.setdefault(exp_name, []).append(\n",
    "        (model_name, img_path)\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(experiments)} experiments.\")\n",
    "\n",
    "# Build comparison figures\n",
    "for exp_name, model_images in experiments.items():\n",
    "\n",
    "    model_images.sort(key=lambda x: x[0])\n",
    "    n_models = len(model_images)\n",
    "    if n_models == 0:\n",
    "        continue\n",
    "    rows, cols = best_subplot_shape(n_models)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten() if n_models > 1 else [axes]\n",
    "\n",
    "    for ax, (model_name, img_path) in zip(axes, model_images):\n",
    "        lp = long_path(img_path)\n",
    "        img = Image.open(lp)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(model_name, fontsize=8)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for ax in axes[n_models:]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_name = shorten_experiment_name(exp_name) + \".png\"\n",
    "    save_path = output_dir / save_name\n",
    "    plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
